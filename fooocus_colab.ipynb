{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjYy0F2gZIPR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35e1966f-771c-4a97-dc39-30a358959ba7"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pygit2==1.15.1\n",
            "  Downloading pygit2-1.15.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: cffi>=1.16.0 in /usr/local/lib/python3.12/dist-packages (from pygit2==1.15.1) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.16.0->pygit2==1.15.1) (2.22)\n",
            "Downloading pygit2-1.15.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m72.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pygit2\n",
            "  Attempting uninstall: pygit2\n",
            "    Found existing installation: pygit2 1.18.2\n",
            "    Uninstalling pygit2-1.18.2:\n",
            "      Successfully uninstalled pygit2-1.18.2\n",
            "Successfully installed pygit2-1.15.1\n",
            "/content\n",
            "Cloning into 'Fooocus'...\n",
            "remote: Enumerating objects: 6725, done.\u001b[K\n",
            "remote: Total 6725 (delta 0), reused 0 (delta 0), pack-reused 6725 (from 1)\u001b[K\n",
            "Receiving objects: 100% (6725/6725), 33.35 MiB | 19.69 MiB/s, done.\n",
            "Resolving deltas: 100% (3845/3845), done.\n",
            "/content/Fooocus\n",
            "Already up-to-date\n",
            "Update succeeded.\n",
            "[System ARGV] ['entry_with_update.py', '--share', '--always-high-vram']\n",
            "/content/Fooocus/build_launcher.py:9: SyntaxWarning: invalid escape sequence '\\p'\n",
            "  .\\python_embeded\\python.exe -s Fooocus\\entry_with_update.py {cmds} %*\n",
            "Python 3.12.11 (main, Jun  4 2025, 08:56:18) [GCC 11.4.0]\n",
            "Fooocus version: 2.5.5\n",
            "Error checking version for torchsde: No package metadata was found for torchsde\n",
            "Installing requirements\n",
            "[Cleanup] Attempting to delete content of temp dir /tmp/fooocus\n",
            "[Cleanup] Cleanup successful\n",
            "Downloading: \"https://huggingface.co/lllyasviel/misc/resolve/main/xlvaeapp.pth\" to /content/Fooocus/models/vae_approx/xlvaeapp.pth\n",
            "\n",
            "100% 209k/209k [00:00<00:00, 11.9MB/s]\n",
            "Downloading: \"https://huggingface.co/lllyasviel/misc/resolve/main/vaeapp_sd15.pt\" to /content/Fooocus/models/vae_approx/vaeapp_sd15.pth\n",
            "\n",
            "100% 209k/209k [00:00<00:00, 9.64MB/s]\n",
            "Downloading: \"https://huggingface.co/mashb1t/misc/resolve/main/xl-to-v1_interposer-v4.0.safetensors\" to /content/Fooocus/models/vae_approx/xl-to-v1_interposer-v4.0.safetensors\n",
            "\n",
            "100% 5.40M/5.40M [00:00<00:00, 97.1MB/s]\n",
            "Downloading: \"https://huggingface.co/lllyasviel/misc/resolve/main/fooocus_expansion.bin\" to /content/Fooocus/models/prompt_expansion/fooocus_expansion/pytorch_model.bin\n",
            "\n",
            "100% 335M/335M [00:01<00:00, 344MB/s]\n",
            "Downloading: \"https://huggingface.co/lllyasviel/fav_models/resolve/main/fav/juggernautXL_v8Rundiffusion.safetensors\" to /content/Fooocus/models/checkpoints/juggernautXL_v8Rundiffusion.safetensors\n",
            "\n",
            "100% 6.62G/6.62G [00:54<00:00, 131MB/s]\n",
            "Downloading: \"https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/sd_xl_offset_example-lora_1.0.safetensors\" to /content/Fooocus/models/loras/sd_xl_offset_example-lora_1.0.safetensors\n",
            "\n",
            "100% 47.3M/47.3M [00:00<00:00, 276MB/s]\n",
            "Total VRAM 15095 MB, total RAM 12978 MB\n",
            "Set vram state to: HIGH_VRAM\n",
            "Always offload VRAM\n",
            "Device: cuda:0 Tesla T4 : native\n",
            "VAE dtype: torch.float32\n",
            "Using pytorch cross attention\n",
            "/content/Fooocus/ldm_patched/unipc/uni_pc.py:56: SyntaxWarning: invalid escape sequence '\\h'\n",
            "  The `alphas_cumprod` is the \\hat{alpha_n} arrays in the notations of DDPM. Specifically, DDPMs assume that\n",
            "Refiner unloaded.\n",
            "IMPORTANT: You are using gradio version 3.41.2, however version 4.44.1 is available, please upgrade.\n",
            "--------\n",
            "Running on local URL:  http://127.0.0.1:7865\n",
            "Running on public URL: https://1c19f7ae0edc21f0d0.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n",
            "model_type EPS\n",
            "UNet ADM Dimension 2816\n",
            "Using pytorch attention in VAE\n",
            "Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
            "Using pytorch attention in VAE\n",
            "extra {'cond_stage_model.clip_l.text_projection', 'cond_stage_model.clip_l.logit_scale'}\n",
            "left over keys: dict_keys(['cond_stage_model.clip_l.transformer.text_model.embeddings.position_ids'])\n",
            "loaded straight to GPU\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "Base model loaded: /content/Fooocus/models/checkpoints/juggernautXL_v8Rundiffusion.safetensors\n",
            "VAE loaded: None\n",
            "Request to load LoRAs [('sd_xl_offset_example-lora_1.0.safetensors', 0.1)] for model [/content/Fooocus/models/checkpoints/juggernautXL_v8Rundiffusion.safetensors].\n",
            "Loaded LoRA [/content/Fooocus/models/loras/sd_xl_offset_example-lora_1.0.safetensors] for UNet [/content/Fooocus/models/checkpoints/juggernautXL_v8Rundiffusion.safetensors] with 788 keys at weight 0.1.\n",
            "Fooocus V2 Expansion: Vocab with 642 words.\n",
            "Fooocus Expansion engine loaded for cuda:0, use_fp16 = True.\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.62 seconds\n",
            "2025-08-25 21:33:40.375128: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1756157620.630096    3726 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1756157620.700087    3726 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1756157621.208865    3726 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756157621.208904    3726 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756157621.208920    3726 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756157621.208927    3726 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-08-25 21:33:41.264686: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Started worker with PID 2970\n",
            "App started successful. Use the app with http://127.0.0.1:7865/ or 127.0.0.1:7865 or https://1c19f7ae0edc21f0d0.gradio.live\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 1120393384294248195\n",
            "[Parameters] CFG = 4\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 30 - 15\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] A 24 year old woman sitting on her couch. She has pink hair, full color, cute confident attractive detailed perfect sweet, gentle, glowing, intricate, sharp focus, still, highly saturated colors, dramatic, cinematic, elegant, professional, sublime, extremely inspirational, stunning, beautiful, symmetry, clear, aesthetic, very fine, innocent, vibrant, inspired, pretty, illuminated\n",
            "[Fooocus] Preparing Fooocus text #2 ...\n",
            "[Prompt Expansion] A 24 year old woman sitting on her couch. She has pink hair, flawless beautiful shining full detailed perfect cute pretty glossy deep very strong sharp focus color, directed burning gorgeous modern stylish cinematic great composition, dramatic atmosphere, dynamic light, aesthetic, shiny, intricate, highly detail, rich vivid colors, amazing cozy warm nice background, lovely expressive epic artistic, neat coherent symmetry, complex\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.14 seconds\n",
            "[Fooocus] Encoding positive #2 ...\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Encoding negative #2 ...\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (896, 1152)\n",
            "Preparation time: 4.13 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/2 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.57 seconds\n",
            "100% 30/30 [00:28<00:00,  1.05it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.27 seconds\n",
            "[Fooocus] Saving image 1/2 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-08-25/log.html\n",
            "Generating and saving time: 33.42 seconds\n",
            "[Fooocus] Preparing task 2/2 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.64 seconds\n",
            "100% 30/30 [00:28<00:00,  1.04it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.26 seconds\n",
            "[Fooocus] Saving image 2/2 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-08-25/log.html\n",
            "Generating and saving time: 32.48 seconds\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 65.90 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 70.08 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.78 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 7183383263213751351\n",
            "[Parameters] CFG = 4\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 30\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] A 24 year old woman sitting on her car. She has blackhair, bright color, cute flawless perfect light, detailed, amazing full focus, very artistic, great composition, dramatic cinematic, elegant, confident, vibrant colors, highly detail, stunning, inspired, rich deep aesthetic, intricate, beautiful dynamic, lovely scenic background, creative, positive, joyful, pure, unique\n",
            "[Fooocus] Preparing Fooocus text #2 ...\n",
            "[Prompt Expansion] A 24 year old woman sitting on her car. She has blackhair, very serious, dramatic, expressive, confident, charismatic, beautiful, deep focus, intricate, elegant, highly detailed, colorful, pleasant, attractive, theatrical, background, sharp detail, elaborate excellent composition, dynamic light, nice atmosphere, engaging, innocent, vibrant color, lovely, aesthetic, pretty, fine\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.13 seconds\n",
            "[Fooocus] Encoding positive #2 ...\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Encoding negative #2 ...\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (896, 1152)\n",
            "Preparation time: 2.03 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/2 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.16 seconds\n",
            "100% 60/60 [00:53<00:00,  1.11it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.33 seconds\n",
            "[Fooocus] Saving image 1/2 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-08-25/log.html\n",
            "Generating and saving time: 58.11 seconds\n",
            "[Fooocus] Preparing task 2/2 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.60 seconds\n",
            "100% 60/60 [00:51<00:00,  1.15it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.27 seconds\n",
            "[Fooocus] Saving image 2/2 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-08-25/log.html\n",
            "Generating and saving time: 55.53 seconds\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 113.63 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 115.72 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.87 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 7482612544281599819\n",
            "[Parameters] CFG = 4\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 30\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] A 24 year old woman sitting iside car, very artistic, full color, dramatic, elaborate illuminated intricate detailed background, complimentary colors, perfect composition, beautiful cinematic atmosphere, dynamic light, exquisite detail, creative, positive, unique, attractive, aesthetic, sharp focus, cheerful, cute, adorable, magical, surreal, iconic, fine, ambient, deep vivid, complex, highly\n",
            "[Fooocus] Preparing Fooocus text #2 ...\n",
            "[Prompt Expansion] A 24 year old woman sitting iside car, joyful, perfect detailed, amazing composition, sharp focus, very inspirational, colorful, elaborate stunning, creative, vibrant, strong colors, light cute, inspired, background created, iconic, fine candid, brilliant, epic, cinematic, highly enhanced, innocent, artistic, pure, beautiful, dramatic ambient, rich deep color, illuminated\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.12 seconds\n",
            "[Fooocus] Encoding positive #2 ...\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Encoding negative #2 ...\n",
            "[Fooocus] Image processing ...\n",
            "[Fooocus] VAE encoding ...\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.83 seconds\n",
            "Final resolution is (1152, 896).\n",
            "[Parameters] Denoising Strength = 0.5\n",
            "[Parameters] Initial Latent shape: torch.Size([1, 4, 112, 144])\n",
            "Preparation time: 4.39 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/2 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 1.2431749105453491\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.56 seconds\n",
            " 27% 16/60 [00:15<00:42,  1.04it/s]\n",
            "User stopped\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 15.95 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 20.37 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.75 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 7284121135095715205\n",
            "[Parameters] CFG = 4\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 30\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] A 24 year old woman sitting inside car, very artistic, fine detail, elegant, sharp focus, intricate, detailed, confident, full color, cinematic, refreshing, vibrant, rational, shiny, pretty, dramatic, background, illuminated, atmosphere, gorgeous, glossy, strong, crisp, light, unique, amazing, expressive, attractive, delicate, creative, cool, cute\n",
            "[Fooocus] Preparing Fooocus text #2 ...\n",
            "[Prompt Expansion] A 24 year old woman sitting inside car, very artistic, beautiful, intricate, highly detailed, dramatic light, sharp focus, illuminated background, elegant, perfect composition, professional, stunning, cute, best, creative, innocent, attractive, pretty, smart, surreal, iconic, deep aesthetic, cool, futuristic, fancy, full color, amazing, emotional, gorgeous, magical\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.12 seconds\n",
            "[Fooocus] Encoding positive #2 ...\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Encoding negative #2 ...\n",
            "[Fooocus] Image processing ...\n",
            "[Fooocus] VAE encoding ...\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.83 seconds\n",
            "Final resolution is (1152, 896).\n",
            "[Parameters] Denoising Strength = 0.5\n",
            "[Parameters] Initial Latent shape: torch.Size([1, 4, 112, 144])\n",
            "Preparation time: 4.32 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/2 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 1.2431749105453491\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.57 seconds\n",
            " 48% 29/60 [00:27<00:29,  1.05it/s]\n",
            "User stopped\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 28.06 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 32.41 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.80 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 6814045373810687205\n",
            "[Parameters] CFG = 4\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 30\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Image processing ...\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (896, 1152)\n",
            "Preparation time: 0.00 seconds\n",
            "Using karras scheduler.\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 0.00 seconds\n",
            "Total time: 1.95 seconds\n",
            "Could not find metadata in the image!\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 979584464100209528\n",
            "[Parameters] CFG = 4\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 30\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "Request to load LoRAs [] for model [/content/Fooocus/models/checkpoints/juggernautXL_v8Rundiffusion.safetensors].\n",
            "Requested to load SDXLClipModel\n",
            "Loading 1 new model\n",
            "unload clone 1\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.14 seconds\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] woman sitting inside car, full detail, sharp focus, beautiful, cinematic, highly detailed, intricate, elegant, professional, bright colors, surreal, thought, ambient light, dynamic background, magic, scenic, vibrant, designed, vivid, complex, dramatic, color, illuminated, clear, artistic, best, adapted, fair, thoughtful, healthy, relaxed, cozy, loving\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.11 seconds\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (896, 1152)\n",
            "Preparation time: 2.58 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/1 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.69 seconds\n",
            "100% 60/60 [00:53<00:00,  1.11it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.17 seconds\n",
            "[Fooocus] Saving image 1/1 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-08-25/log.html\n",
            "Generating and saving time: 57.45 seconds\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 57.45 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 60.06 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.78 seconds\n",
            "Loaded preset: /content/Fooocus/presets/realistic.json\n",
            "Downloading: \"https://huggingface.co/lllyasviel/fav_models/resolve/main/fav/realisticStockPhoto_v20.safetensors\" to /content/Fooocus/models/checkpoints/realisticStockPhoto_v20.safetensors\n",
            "\n",
            "100% 6.46G/6.46G [00:40<00:00, 170MB/s]\n",
            "Downloading: \"https://huggingface.co/mashb1t/fav_models/resolve/main/fav/SDXL_FILM_PHOTOGRAPHY_STYLE_V1.safetensors\" to /content/Fooocus/models/loras/SDXL_FILM_PHOTOGRAPHY_STYLE_V1.safetensors\n",
            "\n",
            "100% 870M/870M [00:05<00:00, 174MB/s]\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 857780475599408294\n",
            "[Parameters] CFG = 3\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 30\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "model_type EPS\n",
            "UNet ADM Dimension 2816\n",
            "Using pytorch attention in VAE\n",
            "Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
            "Using pytorch attention in VAE\n",
            "extra {'cond_stage_model.clip_l.text_projection', 'cond_stage_model.clip_l.logit_scale'}\n",
            "left over keys: dict_keys(['cond_stage_model.clip_l.transformer.text_model.embeddings.position_ids'])\n",
            "loaded straight to GPU\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 2.14 seconds\n",
            "Base model loaded: /content/Fooocus/models/checkpoints/realisticStockPhoto_v20.safetensors\n",
            "VAE loaded: None\n",
            "Request to load LoRAs [('SDXL_FILM_PHOTOGRAPHY_STYLE_V1.safetensors', 0.25)] for model [/content/Fooocus/models/checkpoints/realisticStockPhoto_v20.safetensors].\n",
            "Loaded LoRA [/content/Fooocus/models/loras/SDXL_FILM_PHOTOGRAPHY_STYLE_V1.safetensors] for UNet [/content/Fooocus/models/checkpoints/realisticStockPhoto_v20.safetensors] with 722 keys at weight 0.25.\n",
            "Loaded LoRA [/content/Fooocus/models/loras/SDXL_FILM_PHOTOGRAPHY_STYLE_V1.safetensors] for CLIP [/content/Fooocus/models/checkpoints/realisticStockPhoto_v20.safetensors] with 264 keys at weight 0.25.\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.23 seconds\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] Realistic portrait of hot Swedish 21 year old model, blonde hair, blue eyes, serious, elegant, highly detailed, very beautiful, delicate, inspired, intricate, innocent, illuminated, warm light, divine, dramatic, background, professional, artistic, pure, sincere, passionate, magical, cute, sharp focus, extremely fine detail, colorful, color, clear, cinematic\n",
            "[Fooocus] Preparing Fooocus text #2 ...\n",
            "[Prompt Expansion] Realistic portrait of hot Swedish 21 year old model, blonde hair, blue eyes, cute, modern stylish, massive glowing holy light, intricate, elegant, highly detailed, extremely sharp focus, innocent, sublime, dramatic cinematic color, bright colors, mystical, peaceful, illuminated, beautiful, magical, deep aesthetic, very inspirational, inspiring, noble, determined, rich, colorful background\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.11 seconds\n",
            "[Fooocus] Encoding positive #2 ...\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Encoding negative #2 ...\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (1152, 896)\n",
            "Preparation time: 40.36 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/2 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.69 seconds\n",
            "100% 60/60 [00:58<00:00,  1.03it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.24 seconds\n",
            "[Fooocus] Saving image 1/2 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-08-25/log.html\n",
            "Generating and saving time: 62.73 seconds\n",
            "[Fooocus] Preparing task 2/2 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.72 seconds\n",
            "100% 60/60 [00:54<00:00,  1.09it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.23 seconds\n",
            "[Fooocus] Saving image 2/2 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-08-25/log.html\n",
            "Generating and saving time: 58.58 seconds\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 121.31 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 161.72 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.93 seconds\n",
            "Loaded preset: /content/Fooocus/presets/realistic.json\n",
            "Loaded preset: /content/Fooocus/presets/realistic.json\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 8878918151836536022\n",
            "[Parameters] CFG = 3\n",
            "[Fooocus] Downloading control models ...\n",
            "Downloading: \"https://huggingface.co/lllyasviel/misc/resolve/main/clip_vision_vit_h.safetensors\" to /content/Fooocus/models/clip_vision/clip_vision_vit_h.safetensors\n",
            "\n",
            "100% 1.84G/1.84G [00:40<00:00, 48.7MB/s]\n",
            "Downloading: \"https://huggingface.co/lllyasviel/misc/resolve/main/fooocus_ip_negative.safetensors\" to /content/Fooocus/models/controlnet/fooocus_ip_negative.safetensors\n",
            "\n",
            "100% 64.1k/64.1k [00:00<00:00, 5.14MB/s]\n",
            "Downloading: \"https://huggingface.co/lllyasviel/misc/resolve/main/ip-adapter-plus-face_sdxl_vit-h.bin\" to /content/Fooocus/models/controlnet/ip-adapter-plus-face_sdxl_vit-h.bin\n",
            "\n",
            "100% 967M/967M [00:04<00:00, 240MB/s]\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 30 - 15\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] Blonde Swedish model taking a selfie in a mirror, casual crop top and jeans, soft daylight, full perfect, detailed, beautiful intricate complex artistic color, sharp focus, symmetry, innocent, highly coherent, cute, aesthetic, professional, charismatic, graceful, extremely inspirational, cinematic, gorgeous, dramatic light, best, fine detail, glowing colors, vibrant, epic, stunning\n",
            "[Fooocus] Preparing Fooocus text #2 ...\n",
            "[Prompt Expansion] Blonde Swedish model taking a selfie in a mirror, casual crop top and jeans, soft daylight, cinematic, intricate, elegant, highly detailed, extremely, quality, very coherent, sharp focus, candid, beautiful, cute, innocent, inspired, pretty, iconic, fine, epic, artistic, pure light, deep background, aesthetic, amazing, inspiring, noble, full color\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.12 seconds\n",
            "[Fooocus] Encoding positive #2 ...\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Encoding negative #2 ...\n",
            "[Fooocus] Image processing ...\n",
            "Downloading: \"https://github.com/xinntao/facexlib/releases/download/v0.1.0/detection_Resnet50_Final.pth\" to /content/Fooocus/models/controlnet/detection_Resnet50_Final.pth\n",
            "\n",
            "100% 104M/104M [00:00<00:00, 307MB/s] \n",
            "Downloading: \"https://github.com/xinntao/facexlib/releases/download/v0.2.2/parsing_parsenet.pth\" to /content/Fooocus/models/controlnet/parsing_parsenet.pth\n",
            "\n",
            "100% 81.4M/81.4M [00:00<00:00, 250MB/s]\n",
            "Detected 1 faces\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.70 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.42 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.26 seconds\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (1024, 1024)\n",
            "Preparation time: 64.87 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/2 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 4.86 seconds\n",
            "100% 30/30 [00:29<00:00,  1.01it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.24 seconds\n",
            "[Fooocus] Saving image 1/2 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-08-26/log.html\n",
            "Generating and saving time: 37.58 seconds\n",
            "[Fooocus] Preparing task 2/2 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.72 seconds\n",
            "100% 30/30 [00:27<00:00,  1.08it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.23 seconds\n",
            "[Fooocus] Saving image 2/2 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-08-26/log.html\n",
            "Generating and saving time: 31.26 seconds\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 68.84 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 133.76 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 2.09 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 8585371493115440639\n",
            "[Parameters] CFG = 3\n",
            "[Fooocus] Downloading control models ...\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 30\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] taking a selfie with iphone 14 pro in a mirror, casual crop top and jeans, soft daylight, perfect dynamic composition, symmetry, great focus, ambient light, intricate, detailed, very inspirational, innocent, beautiful, inspired, color, illuminated, cinematic, dramatic, thought taking, creative, epic, best, real, fine detail, pretty, surreal, calm\n",
            "[Fooocus] Preparing Fooocus text #2 ...\n",
            "[Prompt Expansion] taking a selfie with iphone 14 pro in a mirror, casual crop top and jeans, soft daylight, very coherent, sharp focus, sublime, extremely detailed, cinematic, bright colors, ambient light, dynamic background, beautiful, elegant, intricate, highly structured, professional fine detail, rich deep color, illuminated glowing, great composition, clear, aesthetic, perfect, innocent\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.11 seconds\n",
            "[Fooocus] Encoding positive #2 ...\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Encoding negative #2 ...\n",
            "[Fooocus] Image processing ...\n",
            "Detected 1 faces\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.86 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.46 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.26 seconds\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (896, 1152)\n",
            "Preparation time: 6.82 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/2 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.80 seconds\n",
            "100% 60/60 [00:58<00:00,  1.03it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.27 seconds\n",
            "[Fooocus] Saving image 1/2 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-08-26/log.html\n",
            "Generating and saving time: 61.59 seconds\n",
            "[Fooocus] Preparing task 2/2 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.71 seconds\n",
            "100% 60/60 [00:55<00:00,  1.09it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.23 seconds\n",
            "[Fooocus] Saving image 2/2 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-08-26/log.html\n",
            "Generating and saving time: 58.82 seconds\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 120.40 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 127.27 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.90 seconds\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Fooocus/modules/gradio_hijack.py\", line 279, in preprocess\n",
            "    im = processing_utils.decode_base64_to_image(x)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/processing_utils.py\", line 59, in decode_base64_to_image\n",
            "    img = Image.open(BytesIO(base64.b64decode(image_encoded)))\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/PIL/Image.py\", line 3498, in open\n",
            "    raise UnidentifiedImageError(msg)\n",
            "PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x79456ee65df0>\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/routes.py\", line 488, in run_predict\n",
            "    output = await app.get_blocks().process_api(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/blocks.py\", line 1429, in process_api\n",
            "    inputs = self.preprocess_data(fn_index, inputs, state)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/blocks.py\", line 1239, in preprocess_data\n",
            "    processed_input.append(block.preprocess(inputs[i]))\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/modules/gradio_hijack.py\", line 281, in preprocess\n",
            "    raise Error(\"Unsupported image type in input\")\n",
            "gradio.exceptions.Error: 'Unsupported image type in input'\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 8585371493115440639\n",
            "[Parameters] CFG = 3\n",
            "[Fooocus] Downloading control models ...\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 30\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.14 seconds\n",
            "[Fooocus] Encoding positive #2 ...\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Encoding negative #2 ...\n",
            "[Fooocus] Image processing ...\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Fooocus/modules/async_worker.py\", line 1471, in worker\n",
            "    handler(task)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/modules/async_worker.py\", line 1209, in handler\n",
            "    apply_control_nets(async_task, height, ip_adapter_face_path, ip_adapter_path, width, current_progress)\n",
            "  File \"/content/Fooocus/modules/async_worker.py\", line 432, in apply_control_nets\n",
            "    cn_img = HWC3(cn_img)\n",
            "             ^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/modules/util.py\", line 134, in HWC3\n",
            "    assert x.dtype == np.uint8\n",
            "           ^^^^^^^\n",
            "AttributeError: 'tuple' object has no attribute 'dtype'\n",
            "Total time: 0.94 seconds\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Fooocus/modules/gradio_hijack.py\", line 279, in preprocess\n",
            "    im = processing_utils.decode_base64_to_image(x)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/processing_utils.py\", line 59, in decode_base64_to_image\n",
            "    img = Image.open(BytesIO(base64.b64decode(image_encoded)))\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/PIL/Image.py\", line 3498, in open\n",
            "    raise UnidentifiedImageError(msg)\n",
            "PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x79474bdd2430>\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/routes.py\", line 488, in run_predict\n",
            "    output = await app.get_blocks().process_api(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/blocks.py\", line 1429, in process_api\n",
            "    inputs = self.preprocess_data(fn_index, inputs, state)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/blocks.py\", line 1239, in preprocess_data\n",
            "    processed_input.append(block.preprocess(inputs[i]))\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/modules/gradio_hijack.py\", line 281, in preprocess\n",
            "    raise Error(\"Unsupported image type in input\")\n",
            "gradio.exceptions.Error: 'Unsupported image type in input'\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 8585371493115440639\n",
            "[Parameters] CFG = 3\n",
            "[Fooocus] Downloading control models ...\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 30\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 1 new model\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.11 seconds\n",
            "[Fooocus] Encoding positive #2 ...\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Encoding negative #2 ...\n",
            "[Fooocus] Image processing ...\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Fooocus/modules/async_worker.py\", line 1471, in worker\n",
            "    handler(task)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/modules/async_worker.py\", line 1209, in handler\n",
            "    apply_control_nets(async_task, height, ip_adapter_face_path, ip_adapter_path, width, current_progress)\n",
            "  File \"/content/Fooocus/modules/async_worker.py\", line 432, in apply_control_nets\n",
            "    cn_img = HWC3(cn_img)\n",
            "             ^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/modules/util.py\", line 134, in HWC3\n",
            "    assert x.dtype == np.uint8\n",
            "           ^^^^^^^\n",
            "AttributeError: 'tuple' object has no attribute 'dtype'\n",
            "Total time: 0.93 seconds\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Fooocus/modules/gradio_hijack.py\", line 279, in preprocess\n",
            "    im = processing_utils.decode_base64_to_image(x)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/processing_utils.py\", line 59, in decode_base64_to_image\n",
            "    img = Image.open(BytesIO(base64.b64decode(image_encoded)))\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/PIL/Image.py\", line 3498, in open\n",
            "    raise UnidentifiedImageError(msg)\n",
            "PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x794724450a40>\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/routes.py\", line 488, in run_predict\n",
            "    output = await app.get_blocks().process_api(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/blocks.py\", line 1429, in process_api\n",
            "    inputs = self.preprocess_data(fn_index, inputs, state)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/blocks.py\", line 1239, in preprocess_data\n",
            "    processed_input.append(block.preprocess(inputs[i]))\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/modules/gradio_hijack.py\", line 281, in preprocess\n",
            "    raise Error(\"Unsupported image type in input\")\n",
            "gradio.exceptions.Error: 'Unsupported image type in input'\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 8585371493115440639\n",
            "[Parameters] CFG = 3\n",
            "[Fooocus] Downloading control models ...\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 30\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 1 new model\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.11 seconds\n",
            "[Fooocus] Encoding positive #2 ...\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Encoding negative #2 ...\n",
            "[Fooocus] Image processing ...\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Fooocus/modules/async_worker.py\", line 1471, in worker\n",
            "    handler(task)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/modules/async_worker.py\", line 1209, in handler\n",
            "    apply_control_nets(async_task, height, ip_adapter_face_path, ip_adapter_path, width, current_progress)\n",
            "  File \"/content/Fooocus/modules/async_worker.py\", line 432, in apply_control_nets\n",
            "    cn_img = HWC3(cn_img)\n",
            "             ^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/modules/util.py\", line 134, in HWC3\n",
            "    assert x.dtype == np.uint8\n",
            "           ^^^^^^^\n",
            "AttributeError: 'tuple' object has no attribute 'dtype'\n",
            "Total time: 0.91 seconds\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Fooocus/modules/gradio_hijack.py\", line 279, in preprocess\n",
            "    im = processing_utils.decode_base64_to_image(x)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/processing_utils.py\", line 59, in decode_base64_to_image\n",
            "    img = Image.open(BytesIO(base64.b64decode(image_encoded)))\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/PIL/Image.py\", line 3498, in open\n",
            "    raise UnidentifiedImageError(msg)\n",
            "PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x79474bdcb790>\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/routes.py\", line 488, in run_predict\n",
            "    output = await app.get_blocks().process_api(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/blocks.py\", line 1429, in process_api\n",
            "    inputs = self.preprocess_data(fn_index, inputs, state)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/blocks.py\", line 1239, in preprocess_data\n",
            "    processed_input.append(block.preprocess(inputs[i]))\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/modules/gradio_hijack.py\", line 281, in preprocess\n",
            "    raise Error(\"Unsupported image type in input\")\n",
            "gradio.exceptions.Error: 'Unsupported image type in input'\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 8585371493115440639\n",
            "[Parameters] CFG = 3\n",
            "[Fooocus] Downloading control models ...\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 30\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 1 new model\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.11 seconds\n",
            "[Fooocus] Encoding positive #2 ...\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Encoding negative #2 ...\n",
            "[Fooocus] Image processing ...\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Fooocus/modules/async_worker.py\", line 1471, in worker\n",
            "    handler(task)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/modules/async_worker.py\", line 1209, in handler\n",
            "    apply_control_nets(async_task, height, ip_adapter_face_path, ip_adapter_path, width, current_progress)\n",
            "  File \"/content/Fooocus/modules/async_worker.py\", line 432, in apply_control_nets\n",
            "    cn_img = HWC3(cn_img)\n",
            "             ^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/modules/util.py\", line 134, in HWC3\n",
            "    assert x.dtype == np.uint8\n",
            "           ^^^^^^^\n",
            "AttributeError: 'tuple' object has no attribute 'dtype'\n",
            "Total time: 0.94 seconds\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Fooocus/modules/gradio_hijack.py\", line 279, in preprocess\n",
            "    im = processing_utils.decode_base64_to_image(x)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/processing_utils.py\", line 59, in decode_base64_to_image\n",
            "    img = Image.open(BytesIO(base64.b64decode(image_encoded)))\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/PIL/Image.py\", line 3498, in open\n",
            "    raise UnidentifiedImageError(msg)\n",
            "PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x79474bdc8630>\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/routes.py\", line 488, in run_predict\n",
            "    output = await app.get_blocks().process_api(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/blocks.py\", line 1429, in process_api\n",
            "    inputs = self.preprocess_data(fn_index, inputs, state)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/blocks.py\", line 1239, in preprocess_data\n",
            "    processed_input.append(block.preprocess(inputs[i]))\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/modules/gradio_hijack.py\", line 281, in preprocess\n",
            "    raise Error(\"Unsupported image type in input\")\n",
            "gradio.exceptions.Error: 'Unsupported image type in input'\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 8585371493115440639\n",
            "[Parameters] CFG = 3\n",
            "[Fooocus] Downloading control models ...\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 30\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 1 new model\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.11 seconds\n",
            "[Fooocus] Encoding positive #2 ...\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Encoding negative #2 ...\n",
            "[Fooocus] Image processing ...\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Fooocus/modules/async_worker.py\", line 1471, in worker\n",
            "    handler(task)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/modules/async_worker.py\", line 1209, in handler\n",
            "    apply_control_nets(async_task, height, ip_adapter_face_path, ip_adapter_path, width, current_progress)\n",
            "  File \"/content/Fooocus/modules/async_worker.py\", line 432, in apply_control_nets\n",
            "    cn_img = HWC3(cn_img)\n",
            "             ^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/modules/util.py\", line 134, in HWC3\n",
            "    assert x.dtype == np.uint8\n",
            "           ^^^^^^^\n",
            "AttributeError: 'tuple' object has no attribute 'dtype'\n",
            "Total time: 0.94 seconds\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Fooocus/modules/gradio_hijack.py\", line 279, in preprocess\n",
            "    im = processing_utils.decode_base64_to_image(x)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/processing_utils.py\", line 59, in decode_base64_to_image\n",
            "    img = Image.open(BytesIO(base64.b64decode(image_encoded)))\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/PIL/Image.py\", line 3498, in open\n",
            "    raise UnidentifiedImageError(msg)\n",
            "PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x79457889fa60>\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/routes.py\", line 488, in run_predict\n",
            "    output = await app.get_blocks().process_api(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/blocks.py\", line 1429, in process_api\n",
            "    inputs = self.preprocess_data(fn_index, inputs, state)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/blocks.py\", line 1239, in preprocess_data\n",
            "    processed_input.append(block.preprocess(inputs[i]))\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/modules/gradio_hijack.py\", line 281, in preprocess\n",
            "    raise Error(\"Unsupported image type in input\")\n",
            "gradio.exceptions.Error: 'Unsupported image type in input'\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 8585371493115440639\n",
            "[Parameters] CFG = 3\n",
            "[Fooocus] Downloading control models ...\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 30\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 1 new model\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.11 seconds\n",
            "[Fooocus] Encoding positive #2 ...\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Encoding negative #2 ...\n",
            "[Fooocus] Image processing ...\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Fooocus/modules/async_worker.py\", line 1471, in worker\n",
            "    handler(task)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/modules/async_worker.py\", line 1209, in handler\n",
            "    apply_control_nets(async_task, height, ip_adapter_face_path, ip_adapter_path, width, current_progress)\n",
            "  File \"/content/Fooocus/modules/async_worker.py\", line 432, in apply_control_nets\n",
            "    cn_img = HWC3(cn_img)\n",
            "             ^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/modules/util.py\", line 134, in HWC3\n",
            "    assert x.dtype == np.uint8\n",
            "           ^^^^^^^\n",
            "AttributeError: 'tuple' object has no attribute 'dtype'\n",
            "Total time: 0.94 seconds\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Fooocus/modules/gradio_hijack.py\", line 279, in preprocess\n",
            "    im = processing_utils.decode_base64_to_image(x)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/processing_utils.py\", line 59, in decode_base64_to_image\n",
            "    img = Image.open(BytesIO(base64.b64decode(image_encoded)))\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/PIL/Image.py\", line 3498, in open\n",
            "    raise UnidentifiedImageError(msg)\n",
            "PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x794724467a60>\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/routes.py\", line 488, in run_predict\n",
            "    output = await app.get_blocks().process_api(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/blocks.py\", line 1429, in process_api\n",
            "    inputs = self.preprocess_data(fn_index, inputs, state)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/blocks.py\", line 1239, in preprocess_data\n",
            "    processed_input.append(block.preprocess(inputs[i]))\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/modules/gradio_hijack.py\", line 281, in preprocess\n",
            "    raise Error(\"Unsupported image type in input\")\n",
            "gradio.exceptions.Error: 'Unsupported image type in input'\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 8585371493115440639\n",
            "[Parameters] CFG = 3\n",
            "[Fooocus] Downloading control models ...\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 30\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 1 new model\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.11 seconds\n",
            "[Fooocus] Encoding positive #2 ...\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Encoding negative #2 ...\n",
            "[Fooocus] Image processing ...\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Fooocus/modules/async_worker.py\", line 1471, in worker\n",
            "    handler(task)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/modules/async_worker.py\", line 1209, in handler\n",
            "    apply_control_nets(async_task, height, ip_adapter_face_path, ip_adapter_path, width, current_progress)\n",
            "  File \"/content/Fooocus/modules/async_worker.py\", line 432, in apply_control_nets\n",
            "    cn_img = HWC3(cn_img)\n",
            "             ^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/modules/util.py\", line 134, in HWC3\n",
            "    assert x.dtype == np.uint8\n",
            "           ^^^^^^^\n",
            "AttributeError: 'tuple' object has no attribute 'dtype'\n",
            "Total time: 0.94 seconds\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Fooocus/modules/gradio_hijack.py\", line 279, in preprocess\n",
            "    im = processing_utils.decode_base64_to_image(x)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/processing_utils.py\", line 59, in decode_base64_to_image\n",
            "    img = Image.open(BytesIO(base64.b64decode(image_encoded)))\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/PIL/Image.py\", line 3498, in open\n",
            "    raise UnidentifiedImageError(msg)\n",
            "PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x79474bdc80e0>\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/routes.py\", line 488, in run_predict\n",
            "    output = await app.get_blocks().process_api(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/blocks.py\", line 1429, in process_api\n",
            "    inputs = self.preprocess_data(fn_index, inputs, state)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/blocks.py\", line 1239, in preprocess_data\n",
            "    processed_input.append(block.preprocess(inputs[i]))\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/modules/gradio_hijack.py\", line 281, in preprocess\n",
            "    raise Error(\"Unsupported image type in input\")\n",
            "gradio.exceptions.Error: 'Unsupported image type in input'\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 8585371493115440639\n",
            "[Parameters] CFG = 3\n",
            "[Fooocus] Downloading control models ...\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 30\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 1 new model\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.13 seconds\n",
            "[Fooocus] Encoding positive #2 ...\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Encoding negative #2 ...\n",
            "[Fooocus] Image processing ...\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Fooocus/modules/async_worker.py\", line 1471, in worker\n",
            "    handler(task)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/modules/async_worker.py\", line 1209, in handler\n",
            "    apply_control_nets(async_task, height, ip_adapter_face_path, ip_adapter_path, width, current_progress)\n",
            "  File \"/content/Fooocus/modules/async_worker.py\", line 432, in apply_control_nets\n",
            "    cn_img = HWC3(cn_img)\n",
            "             ^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/modules/util.py\", line 134, in HWC3\n",
            "    assert x.dtype == np.uint8\n",
            "           ^^^^^^^\n",
            "AttributeError: 'tuple' object has no attribute 'dtype'\n",
            "Total time: 1.01 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 5221878210712469397\n",
            "[Parameters] CFG = 3\n",
            "[Fooocus] Downloading control models ...\n",
            "Downloading: \"https://huggingface.co/lllyasviel/misc/resolve/main/control-lora-canny-rank128.safetensors\" to /content/Fooocus/models/controlnet/control-lora-canny-rank128.safetensors\n",
            "\n",
            "100% 377M/377M [00:13<00:00, 28.8MB/s]\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 30\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 1 new model\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] Blonde Swedish model taking a selfie with iphone 16 pro in a mirror, casual crop top and jeans, soft daylight, highly detailed, sublime, sharp focus, intricate, very beautiful, innocent, elegant, light glowing, deep aesthetic, excellent composition, ambient dramatic cinematic color, perfect romantic magic, stunning fine detail, creative, positive emotional, pure artistic, wonderful colors\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.11 seconds\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Image processing ...\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (896, 1152)\n",
            "Preparation time: 16.16 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/1 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.12 seconds\n",
            " 12% 7/60 [00:12<01:36,  1.82s/it]\n",
            "User stopped\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 15.41 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 31.59 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 2.11 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 5374454241719867858\n",
            "[Parameters] CFG = 3\n",
            "[Fooocus] Downloading control models ...\n",
            "Downloading: \"https://huggingface.co/lllyasviel/misc/resolve/main/ip-adapter-plus_sdxl_vit-h.bin\" to /content/Fooocus/models/controlnet/ip-adapter-plus_sdxl_vit-h.bin\n",
            "\n",
            "100% 967M/967M [00:21<00:00, 46.6MB/s]\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 30\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] Blonde Swedish model taking a selfie with iphone 16 pro in a mirror, casual crop top and jeans, soft daylight, beautiful detailed intricate cute glowing light, cinematic, highly detail, great composition, dynamic dramatic atmosphere, vibrant colors, focus, elegant, very inspirational, innocent, fine thought, professional amazing, epic artistic, singular, best, creative, positive, unique\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.12 seconds\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Image processing ...\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.85 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.43 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.30 seconds\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (896, 1152)\n",
            "Preparation time: 29.48 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/1 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 4.89 seconds\n",
            "100% 60/60 [00:57<00:00,  1.05it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.24 seconds\n",
            "[Fooocus] Saving image 1/1 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-08-26/log.html\n",
            "Generating and saving time: 64.92 seconds\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 64.92 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 94.44 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.92 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 8315606191154731167\n",
            "[Parameters] CFG = 3\n",
            "[Fooocus] Downloading control models ...\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 30\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] Blonde Swedish model taking a selfie with iphone 16 pro in a mirror, casual crop top and jeans, soft daylight, highly detailed, sharp focus, handsome full color background, divine, sublime, very beautiful, cinematic, rich deep colors, dramatic light, professional, extremely stylish, best, sincere, glowing, attractive, bright, colorful, futuristic, stunning, thought\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.11 seconds\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Image processing ...\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.69 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.40 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.23 seconds\n",
            "Detected 1 faces\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.51 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.42 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.26 seconds\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (896, 1152)\n",
            "Preparation time: 7.31 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/1 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.81 seconds\n",
            "100% 60/60 [00:57<00:00,  1.05it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.25 seconds\n",
            "[Fooocus] Saving image 1/1 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-08-26/log.html\n",
            "Generating and saving time: 60.62 seconds\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 60.62 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 67.95 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.01 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 7453525350997885167\n",
            "[Parameters] CFG = 3\n",
            "[Fooocus] Downloading control models ...\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 30\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] Blonde Swedish model taking a selfie with iphone 16 pro in a mirror, casual crop top and jeans, soft daylight, highly detailed, sharp focus, intricate, elegant, innocent, sublime, pretty, worthy, handsome, modern fine classic cinematic color, deep royal flowing, light glowing, symmetry, brilliant, thought spectacular, imposing, full artistic, epic, enhanced\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.12 seconds\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Image processing ...\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.69 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.40 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.24 seconds\n",
            "Detected 1 faces\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.51 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.41 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.24 seconds\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (896, 1152)\n",
            "Preparation time: 7.04 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/1 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.75 seconds\n",
            "100% 60/60 [00:57<00:00,  1.05it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.25 seconds\n",
            "[Fooocus] Saving image 1/1 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-08-26/log.html\n",
            "Generating and saving time: 60.59 seconds\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 60.59 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 67.65 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.91 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 117022293725702439\n",
            "[Parameters] CFG = 3\n",
            "[Fooocus] Downloading control models ...\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 30\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] Blonde Swedish model taking a selfie with iphone front a mirror, casual crop top and jeans, soft daylight, highly detailed, sharp focus, beautiful intricate, innocent, sublime, dramatic light, cinematic, fine detail, complex, elegant, crisp quality, vibrant colors, surreal background, inspired, famous, illustrious, romantic, iconic, brave, illuminated, magnificent, full\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.12 seconds\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Image processing ...\n",
            "Detected 1 faces\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.71 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.44 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.24 seconds\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (896, 1152)\n",
            "Preparation time: 6.19 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/1 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.84 seconds\n",
            " 67% 40/60 [00:39<00:19,  1.03it/s]\n",
            "User stopped\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 39.86 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 46.08 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.86 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 1096661698184343851\n",
            "[Parameters] CFG = 3\n",
            "[Fooocus] Downloading control models ...\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 30\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] Blonde Swedish model taking a selfie with last iphone front a mirror, casual crop top and jeans, soft daylight, highly detailed, fine detail, intricate, beautiful, elegant, luxury, dramatic ambient light, sharp focus, pretty background, professional, clear excellent composition, innocent, expressive, epic, stunning, gorgeous, creative, amazing, emotional, cinematic, very inspirational\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.11 seconds\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Image processing ...\n",
            "Detected 1 faces\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.71 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.44 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.24 seconds\n",
            "Detected 1 faces\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.50 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.41 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.21 seconds\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (896, 1152)\n",
            "Preparation time: 9.56 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/1 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.81 seconds\n",
            "100% 60/60 [00:58<00:00,  1.03it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.24 seconds\n",
            "[Fooocus] Saving image 1/1 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-08-26/log.html\n",
            "Generating and saving time: 61.74 seconds\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 61.74 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 71.33 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.04 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 319469408987244516\n",
            "[Parameters] CFG = 3\n",
            "[Fooocus] Downloading control models ...\n",
            "Downloading: \"https://huggingface.co/lllyasviel/misc/resolve/main/fooocus_xl_cpds_128.safetensors\" to /content/Fooocus/models/controlnet/fooocus_xl_cpds_128.safetensors\n",
            "\n",
            "100% 377M/377M [00:06<00:00, 59.8MB/s]\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 30\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] model taking a selfie with last iphone front a mirror, casual crop top and jeans, soft daylight, cinematic, highly detailed, advanced, rich deep, complex, dramatic light, epic composition, atmosphere, calm, delicate, artistic, innocent, symbolic, strong, confident, inspired, color, illuminated, pretty, attractive, elite, sharp, excellent, perfect, extremely\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.15 seconds\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Image processing ...\n",
            "Detected 1 faces\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.73 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.44 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.24 seconds\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (896, 1152)\n",
            "Preparation time: 13.38 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/1 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.77 seconds\n",
            " 32% 19/60 [00:30<01:05,  1.60s/it]\n",
            "User stopped\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 31.38 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 44.79 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.91 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 4719668613345911155\n",
            "[Parameters] CFG = 3\n",
            "[Fooocus] Downloading control models ...\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 30\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] model taking a selfie with last iphone front a mirror, casual crop top and jeans, soft daylight, highly detailed, sublime, sharp focus, intricate, very stylish, cinematic, candid, true magic, illuminated, professional, extremely rare, fantastic, creative, positive, pure, color, beautiful, elegant, cute, magical, surreal, inspired, symmetry, fine detail\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.11 seconds\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Image processing ...\n",
            "Detected 1 faces\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.70 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.42 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.23 seconds\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (896, 1152)\n",
            "Preparation time: 6.61 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/1 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.80 seconds\n",
            " 95% 57/60 [01:09<00:03,  1.21s/it]\n",
            "User stopped\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 70.23 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 76.86 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.86 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 1981963162346173383\n",
            "[Parameters] CFG = 3\n",
            "[Fooocus] Downloading control models ...\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 30\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] model taking a selfie with last iphone front a mirror, casual crop top and jeans, soft daylight, highly detailed, advanced, intricate, sharp focus, formal, elegant, professional, bright colors, illuminated background, beautiful, extremely, cinematic, stunning, enhanced quality, very, futuristic, thought beaten, innocent, rich, inspiring, dramatic, artistic, cute, charming\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.13 seconds\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Image processing ...\n",
            "Detected 1 faces\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.70 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.43 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.23 seconds\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (896, 1152)\n",
            "Preparation time: 7.05 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/1 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.76 seconds\n",
            " 90% 54/60 [01:06<00:07,  1.24s/it]\n",
            "User stopped\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 69.05 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 76.11 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.89 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 5396413817492650173\n",
            "[Parameters] CFG = 3\n",
            "[Fooocus] Downloading control models ...\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 30\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] model taking a selfie with last iphone front a mirror, casual crop top and jeans, soft daylight, highly detailed, sharp focus, beautiful, very stylish, cinematic, sunny, background, bright, shiny, deep, vivid, true colors, illuminated, epic, joyful, thought, full color, radiant, romantic, intricate, extremely, stunning, enhanced quality, artistic\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.12 seconds\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Image processing ...\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.68 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.39 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.25 seconds\n",
            "Detected 1 faces\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.50 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.41 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.23 seconds\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (960, 1088)\n",
            "Preparation time: 7.08 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/1 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.75 seconds\n",
            " 10% 6/60 [00:06<00:59,  1.09s/it]\n",
            "User stopped\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 7.33 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 14.43 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.84 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 8058484092240301908\n",
            "[Parameters] CFG = 3\n",
            "[Fooocus] Downloading control models ...\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 30\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] model taking a selfie with last iphone front a mirror, casual crop top and jeans, soft daylight, highly detailed, deep aesthetic, intricate, elegant, stylish, sharp focus, beautiful light, professional, cute, expressive, innocent, pretty, illuminated, background dramatic ambient, rich colors, fine detail, great composition, perfect dynamic serious atmosphere, vivid, artistic, very\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.12 seconds\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Image processing ...\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.69 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.40 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.23 seconds\n",
            "Detected 1 faces\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.61 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.41 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.24 seconds\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (1152, 896)\n",
            "Preparation time: 7.74 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/1 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.77 seconds\n",
            " 48% 29/60 [00:29<00:31,  1.00s/it]\n",
            "User stopped\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 29.89 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 37.65 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.86 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 5989469502564739585\n",
            "[Parameters] CFG = 3\n",
            "[Fooocus] Downloading control models ...\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 30\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] model taking a selfie front a mirror, casual crop top and jeans, soft daylight, highly detailed, sharp focus, beautiful, intricate, innocent, elegant, designed, background inspired, pretty light, cinematic, bright color, modern, shiny, colorful, professional, extremely, illuminated, amazing, daring, dramatic ambient, artistic, thought, perfect, lovely, confident, trendy\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.12 seconds\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Image processing ...\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.65 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.37 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.22 seconds\n",
            "Detected 1 faces\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.50 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.41 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.22 seconds\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (1152, 896)\n",
            "Preparation time: 6.90 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/1 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.77 seconds\n",
            " 45% 27/60 [00:26<00:32,  1.02it/s]\n",
            "User stopped\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 27.22 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 34.15 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.86 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 6469443508659316162\n",
            "[Parameters] CFG = 3\n",
            "[Fooocus] Downloading control models ...\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 30\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] model takes a selfie with her phone horizontally in front of a mirror, wearing a casual crop top and jeans, in soft daylight, highly detailed, sharp focus, very coherent, ambient light, cinematic, dynamic background, rich colors, magic, true color, elegant, intricate, perfect composition, innocent, vivid, aesthetic, extremely inspirational, fine detail, full, colorful, stunning\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.12 seconds\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Image processing ...\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.70 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.40 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.24 seconds\n",
            "Detected 1 faces\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.59 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.45 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.24 seconds\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (1152, 896)\n",
            "Preparation time: 7.70 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/1 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.79 seconds\n",
            "100% 60/60 [00:57<00:00,  1.04it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.29 seconds\n",
            "[Fooocus] Saving image 1/1 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-08-26/log.html\n",
            "Generating and saving time: 61.30 seconds\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 61.30 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 69.02 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.90 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 8732402126307664752\n",
            "[Parameters] CFG = 3\n",
            "[Fooocus] Downloading control models ...\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 30\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] Realistic portrait of hot Swedish 21 year old model, blonde hair, blue eyes, takes a selfie with her phone horizontally in front of a mirror, wearing a casual crop top and jeans, in soft daylight, highly detailed, focus, handsome, intricate, cinematic light, sharp, very coherent, ambient, rich deep colors, excellent composition, dynamic dramatic atmosphere, creative, positive\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.12 seconds\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Image processing ...\n",
            "Detected 1 faces\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.73 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.44 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.24 seconds\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (1152, 896)\n",
            "Preparation time: 8.02 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/1 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.76 seconds\n",
            "100% 60/60 [01:12<00:00,  1.20s/it]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.25 seconds\n",
            "[Fooocus] Saving image 1/1 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-08-26/log.html\n",
            "Generating and saving time: 76.50 seconds\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 76.50 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 84.56 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.99 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 228935933124619003\n",
            "[Parameters] CFG = 3\n",
            "[Fooocus] Downloading upscale models ...\n",
            "Downloading: \"https://huggingface.co/lllyasviel/misc/resolve/main/fooocus_upscaler_s409985e5.bin\" to /content/Fooocus/models/upscale_models/fooocus_upscaler_s409985e5.bin\n",
            "\n",
            "100% 32.1M/32.1M [00:00<00:00, 277MB/s]\n",
            "[Fooocus] Downloading inpainter ...\n",
            "Downloading: \"https://huggingface.co/lllyasviel/fooocus_inpaint/resolve/main/fooocus_inpaint_head.pth\" to /content/Fooocus/models/inpaint/fooocus_inpaint_head.pth\n",
            "\n",
            "100% 51.4k/51.4k [00:00<00:00, 6.18MB/s]\n",
            "Downloading: \"https://huggingface.co/lllyasviel/fooocus_inpaint/resolve/main/inpaint_v26.fooocus.patch\" to /content/Fooocus/models/inpaint/inpaint_v26.fooocus.patch\n",
            "\n",
            "100% 1.23G/1.23G [00:21<00:00, 60.4MB/s]\n",
            "[Inpaint] Current inpaint model is /content/Fooocus/models/inpaint/inpaint_v26.fooocus.patch\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 48\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Synthetic Refiner Activated\n",
            "Synthetic Refiner Activated\n",
            "Request to load LoRAs [('SDXL_FILM_PHOTOGRAPHY_STYLE_V1.safetensors', 0.25), ('/content/Fooocus/models/inpaint/inpaint_v26.fooocus.patch', 1.0)] for model [/content/Fooocus/models/checkpoints/realisticStockPhoto_v20.safetensors].\n",
            "Loaded LoRA [/content/Fooocus/models/loras/SDXL_FILM_PHOTOGRAPHY_STYLE_V1.safetensors] for UNet [/content/Fooocus/models/checkpoints/realisticStockPhoto_v20.safetensors] with 722 keys at weight 0.25.\n",
            "Loaded LoRA [/content/Fooocus/models/loras/SDXL_FILM_PHOTOGRAPHY_STYLE_V1.safetensors] for CLIP [/content/Fooocus/models/checkpoints/realisticStockPhoto_v20.safetensors] with 264 keys at weight 0.25.\n",
            "Loaded LoRA [/content/Fooocus/models/inpaint/inpaint_v26.fooocus.patch] for UNet [/content/Fooocus/models/checkpoints/realisticStockPhoto_v20.safetensors] with 960 keys at weight 1.0.\n",
            "Request to load LoRAs [('SDXL_FILM_PHOTOGRAPHY_STYLE_V1.safetensors', 0.25)] for model [/content/Fooocus/models/checkpoints/realisticStockPhoto_v20.safetensors].\n",
            "Loaded LoRA [/content/Fooocus/models/loras/SDXL_FILM_PHOTOGRAPHY_STYLE_V1.safetensors] for UNet [/content/Fooocus/models/checkpoints/realisticStockPhoto_v20.safetensors] with 722 keys at weight 0.25.\n",
            "Requested to load SDXLClipModel\n",
            "Loading 1 new model\n",
            "unload clone 1\n",
            "[Fooocus Model Management] Moving model(s) has taken 2.35 seconds\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] wearing a casual crop top and jeans, in soft daylight, cinematic background, highly detailed, sharp focus, cool color light, modern inspired contemporary fine classic very strong handsome professional, authentic, pretty, attractive, smart, extremely, intricate, elegant, dramatic ambient, full composition, creative, positive radiant, lucid, beautiful, aesthetic, glowing, rich deep colors, surreal\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.17 seconds\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Image processing ...\n",
            "Upscaling image with shape (773, 827, 3) ...\n",
            "[Fooocus] VAE Inpaint encoding ...\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.59 seconds\n",
            "[Fooocus] VAE encoding ...\n",
            "Final resolution is (896, 1152), latent is (1088, 960).\n",
            "[Parameters] Denoising Strength = 1\n",
            "[Parameters] Initial Latent shape: torch.Size([1, 4, 120, 136])\n",
            "Preparation time: 51.89 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/1 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 5.27 seconds\n",
            " 80% 48/60 [00:45<00:11,  1.07it/s]Requested to load SDXL\n",
            "Loading 1 new model\n",
            "unload clone 0\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.59 seconds\n",
            "Refiner Swapped\n",
            " 88% 53/60 [00:51<00:06,  1.02it/s]\n",
            "User stopped\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 57.19 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 109.11 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.03 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 8546378075808869784\n",
            "[Parameters] CFG = 3\n",
            "[Fooocus] Downloading upscale models ...\n",
            "[Fooocus] Downloading inpainter ...\n",
            "[Inpaint] Current inpaint model is /content/Fooocus/models/inpaint/inpaint_v26.fooocus.patch\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 48\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Synthetic Refiner Activated\n",
            "Synthetic Refiner Activated\n",
            "Request to load LoRAs [('SDXL_FILM_PHOTOGRAPHY_STYLE_V1.safetensors', 0.25)] for model [/content/Fooocus/models/checkpoints/realisticStockPhoto_v20.safetensors].\n",
            "Loaded LoRA [/content/Fooocus/models/loras/SDXL_FILM_PHOTOGRAPHY_STYLE_V1.safetensors] for UNet [/content/Fooocus/models/checkpoints/realisticStockPhoto_v20.safetensors] with 722 keys at weight 0.25.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] Realistic wearing a casual crop top, dramatic light, luxurious, modern, elaborate, detailed, very surreal, sharp focus, detail, extremely fine, sincere, cute, beautiful, innocent, elegant, confident, complex artistic color background, highly coherent, intricate, epic composition, magical atmosphere, professional, thought, iconic, best, romantic, calm, healing, pure, rational\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.12 seconds\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Image processing ...\n",
            "Upscaling image with shape (773, 827, 3) ...\n",
            "[Fooocus] VAE Inpaint encoding ...\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.61 seconds\n",
            "[Fooocus] VAE encoding ...\n",
            "Final resolution is (896, 1152), latent is (1088, 960).\n",
            "[Parameters] Denoising Strength = 1\n",
            "[Parameters] Initial Latent shape: torch.Size([1, 4, 120, 136])\n",
            "Preparation time: 17.33 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/1 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.36 seconds\n",
            "  0% 0/60 [00:00<?, ?it/s]\n",
            "User stopped\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 2.32 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 19.66 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.86 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 1842357601767195136\n",
            "[Parameters] CFG = 3\n",
            "[Fooocus] Downloading upscale models ...\n",
            "[Fooocus] Downloading inpainter ...\n",
            "[Inpaint] Current inpaint model is /content/Fooocus/models/inpaint/inpaint_v26.fooocus.patch\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 48\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Synthetic Refiner Activated\n",
            "Synthetic Refiner Activated\n",
            "Request to load LoRAs [('SDXL_FILM_PHOTOGRAPHY_STYLE_V1.safetensors', 0.25)] for model [/content/Fooocus/models/checkpoints/realisticStockPhoto_v20.safetensors].\n",
            "Loaded LoRA [/content/Fooocus/models/loras/SDXL_FILM_PHOTOGRAPHY_STYLE_V1.safetensors] for UNet [/content/Fooocus/models/checkpoints/realisticStockPhoto_v20.safetensors] with 722 keys at weight 0.25.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] Realistic wearing a casual crop top, dramatic background, artistic, sublime, cool color, sharp focus, intricate, very expressive, highly detailed, innocent, fine detail, glorious, epic composition, amazing dynamic, cinematic, beautiful scenic, elegant, great light, professional, winning, best, creative, positive, attractive, cheerful, cute, thoughtful, charming, pretty, focused\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.11 seconds\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Image processing ...\n",
            "[Fooocus] VAE Inpaint encoding ...\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.44 seconds\n",
            "[Fooocus] VAE encoding ...\n",
            "Final resolution is (896, 1497), latent is (768, 1280).\n",
            "[Parameters] Denoising Strength = 1\n",
            "[Parameters] Initial Latent shape: torch.Size([1, 4, 160, 96])\n",
            "Preparation time: 6.84 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/1 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.29 seconds\n",
            " 80% 48/60 [00:45<00:10,  1.12it/s]Requested to load SDXL\n",
            "Loading 1 new model\n",
            "unload clone 0\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.59 seconds\n",
            "Refiner Swapped\n",
            "100% 60/60 [00:56<00:00,  1.06it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.24 seconds\n",
            "[Fooocus] Saving image 1/1 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-08-26/log.html\n",
            "Generating and saving time: 60.65 seconds\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 60.65 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 67.53 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.92 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 3323663109813104484\n",
            "[Parameters] CFG = 3\n",
            "[Fooocus] Downloading upscale models ...\n",
            "[Inpaint] Parameterized inpaint is disabled.\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 30\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "Request to load LoRAs [('SDXL_FILM_PHOTOGRAPHY_STYLE_V1.safetensors', 0.25)] for model [/content/Fooocus/models/checkpoints/realisticStockPhoto_v20.safetensors].\n",
            "Loaded LoRA [/content/Fooocus/models/loras/SDXL_FILM_PHOTOGRAPHY_STYLE_V1.safetensors] for UNet [/content/Fooocus/models/checkpoints/realisticStockPhoto_v20.safetensors] with 722 keys at weight 0.25.\n",
            "Loaded LoRA [/content/Fooocus/models/loras/SDXL_FILM_PHOTOGRAPHY_STYLE_V1.safetensors] for CLIP [/content/Fooocus/models/checkpoints/realisticStockPhoto_v20.safetensors] with 264 keys at weight 0.25.\n",
            "Requested to load SDXLClipModel\n",
            "Loading 1 new model\n",
            "unload clone 1\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.96 seconds\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] Realistic wearing, cinematic, extremely detailed, beautiful, intricate, elegant, real,, dramatic, vibrant colors, highly coherent, epic, stunning, gorgeous, creative, pure, amazing detail, pretty, very inspirational, cute, draped, flowing, elaborate, designed, expressive, lovely, perfect, colorful, awesome, colossal, brilliant, fine, complex background, ambient\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.11 seconds\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Image processing ...\n",
            "Upscaling image with shape (773, 827, 3) ...\n",
            "[Fooocus] VAE Inpaint encoding ...\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.52 seconds\n",
            "[Fooocus] VAE encoding ...\n",
            "Final resolution is (896, 1152), latent is (1088, 960).\n",
            "[Parameters] Denoising Strength = 0.5\n",
            "[Parameters] Initial Latent shape: torch.Size([1, 4, 120, 136])\n",
            "Preparation time: 15.44 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/1 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 1.2431749105453491\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.69 seconds\n",
            " 38% 23/60 [00:23<00:37,  1.01s/it]\n",
            "User stopped\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 23.97 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 39.43 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.85 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 5237482237672373974\n",
            "[Parameters] CFG = 3\n",
            "[Fooocus] Downloading upscale models ...\n",
            "[Inpaint] Parameterized inpaint is disabled.\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 30\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] Realistic wearing a casual crop top and jean, beautiful detailed perfect cute pretty highly intricate complex pleasing bright vibrant colorful background inspired scenic dynamic dramatic professional color sharp focus, great composition, spectacular atmosphere, artistic, very inspirational, clear, innocent, elegant, aesthetic, amazing, creative, positive, wonderful, pure, fine detail, extremely attractive, cinematic, stunning, fabulous, symmetry\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.12 seconds\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Image processing ...\n",
            "Upscaling image with shape (773, 827, 3) ...\n",
            "[Fooocus] VAE Inpaint encoding ...\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.51 seconds\n",
            "[Fooocus] VAE encoding ...\n",
            "Final resolution is (896, 1152), latent is (1088, 960).\n",
            "[Parameters] Denoising Strength = 0.5\n",
            "[Parameters] Initial Latent shape: torch.Size([1, 4, 120, 136])\n",
            "Preparation time: 14.70 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/1 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 1.2431749105453491\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.68 seconds\n",
            " 70% 42/60 [00:41<00:17,  1.00it/s]\n",
            "User stopped\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 42.48 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 57.21 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.88 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 8906221048845996501\n",
            "[Parameters] CFG = 3\n",
            "[Fooocus] Downloading control models ...\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 30\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] Realistic wearing a casual crop top and jean, beautiful detailed true cute pretty futuristic winning glossy intricate elegant sharp focus, full detail, attractive sleek vibrant colorful highly formal modern contemporary dynamic ambient background, designed, professional, decorated, great composition, creative, positive, expressive, emotional, lively, exciting, symmetry, unique, awesome, fabulous, gorgeous, fine, stunning, epic\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.11 seconds\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Image processing ...\n",
            "Detected 1 faces\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.76 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.46 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.26 seconds\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (1152, 896)\n",
            "Preparation time: 8.88 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/1 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.78 seconds\n",
            " 77% 46/60 [00:59<00:18,  1.29s/it]\n",
            "User stopped\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 60.90 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 69.79 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.90 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 6922457705406532975\n",
            "[Parameters] CFG = 3\n",
            "[Fooocus] Downloading control models ...\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 30\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] Realistic portrait of hot Swedish 21 year old model, blonde hair, blue eyes, takes a selfie with her phone horizontally in front of a mirror, wearing a casual crop top and jeans, highly detailed, cinematic, extremely aesthetic, sincere coherent, charismatic, determined, very inspirational, glowing, incredible, inspiring, generous, dramatic, thought, magic, sharp focus, intricate\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.12 seconds\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Image processing ...\n",
            "Detected 1 faces\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.75 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.47 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.24 seconds\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (1152, 896)\n",
            "Preparation time: 6.20 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/1 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.88 seconds\n",
            " 77% 46/60 [00:57<00:17,  1.25s/it]\n",
            "User skipped\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 58.91 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 65.12 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.99 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 6249112282786844536\n",
            "[Parameters] CFG = 3\n",
            "[Fooocus] Downloading control models ...\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 30 - 15\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] Realistic portrait of hot Swedish 21 year old model, blonde hair, blue eyes, takes a selfie with her phone horizontally in front of a mirror, wearing a casual crop top and jeans, highly detailed, cinematic, real, beautiful, delicate, elegant, intricate, dramatic, sharp focus, fine detail, calm artistic, complex, vibrant color, iconic, innocent, pretty\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.12 seconds\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Image processing ...\n",
            "Detected 1 faces\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.82 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.50 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.25 seconds\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (1152, 896)\n",
            "Preparation time: 6.60 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/1 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.78 seconds\n",
            "100% 30/30 [00:34<00:00,  1.16s/it]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.32 seconds\n",
            "[Fooocus] Saving image 1/1 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-08-26/log.html\n",
            "Generating and saving time: 38.75 seconds\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 38.75 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 45.37 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.88 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 438555050748416373\n",
            "[Parameters] CFG = 3\n",
            "[Fooocus] Downloading upscale models ...\n",
            "[Fooocus] Downloading inpainter ...\n",
            "[Inpaint] Current inpaint model is /content/Fooocus/models/inpaint/inpaint_v26.fooocus.patch\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 30 - 24\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Synthetic Refiner Activated\n",
            "Synthetic Refiner Activated\n",
            "Request to load LoRAs [('SDXL_FILM_PHOTOGRAPHY_STYLE_V1.safetensors', 0.25), ('/content/Fooocus/models/inpaint/inpaint_v26.fooocus.patch', 1.0)] for model [/content/Fooocus/models/checkpoints/realisticStockPhoto_v20.safetensors].\n",
            "Loaded LoRA [/content/Fooocus/models/loras/SDXL_FILM_PHOTOGRAPHY_STYLE_V1.safetensors] for UNet [/content/Fooocus/models/checkpoints/realisticStockPhoto_v20.safetensors] with 722 keys at weight 0.25.\n",
            "Loaded LoRA [/content/Fooocus/models/loras/SDXL_FILM_PHOTOGRAPHY_STYLE_V1.safetensors] for CLIP [/content/Fooocus/models/checkpoints/realisticStockPhoto_v20.safetensors] with 264 keys at weight 0.25.\n",
            "Loaded LoRA [/content/Fooocus/models/inpaint/inpaint_v26.fooocus.patch] for UNet [/content/Fooocus/models/checkpoints/realisticStockPhoto_v20.safetensors] with 960 keys at weight 1.0.\n",
            "Request to load LoRAs [('SDXL_FILM_PHOTOGRAPHY_STYLE_V1.safetensors', 0.25)] for model [/content/Fooocus/models/checkpoints/realisticStockPhoto_v20.safetensors].\n",
            "Loaded LoRA [/content/Fooocus/models/loras/SDXL_FILM_PHOTOGRAPHY_STYLE_V1.safetensors] for UNet [/content/Fooocus/models/checkpoints/realisticStockPhoto_v20.safetensors] with 722 keys at weight 0.25.\n",
            "Requested to load SDXLClipModel\n",
            "Loading 1 new model\n",
            "unload clone 1\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.04 seconds\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.13 seconds\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Image processing ...\n",
            "Upscaling image with shape (712, 731, 3) ...\n",
            "[Fooocus] VAE Inpaint encoding ...\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.60 seconds\n",
            "[Fooocus] VAE encoding ...\n",
            "Final resolution is (896, 1152), latent is (1024, 960).\n",
            "[Parameters] Denoising Strength = 1\n",
            "[Parameters] Initial Latent shape: torch.Size([1, 4, 120, 128])\n",
            "Preparation time: 22.06 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/1 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.34 seconds\n",
            " 67% 20/30 [00:20<00:10,  1.01s/it]\n",
            "User stopped\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 21.50 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 43.58 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.88 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 5429144493031767238\n",
            "[Parameters] CFG = 3\n",
            "[Fooocus] Downloading upscale models ...\n",
            "[Fooocus] Downloading inpainter ...\n",
            "[Inpaint] Current inpaint model is /content/Fooocus/models/inpaint/inpaint_v26.fooocus.patch\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 30 - 24\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Synthetic Refiner Activated\n",
            "Synthetic Refiner Activated\n",
            "Request to load LoRAs [('SDXL_FILM_PHOTOGRAPHY_STYLE_V1.safetensors', 0.25)] for model [/content/Fooocus/models/checkpoints/realisticStockPhoto_v20.safetensors].\n",
            "Loaded LoRA [/content/Fooocus/models/loras/SDXL_FILM_PHOTOGRAPHY_STYLE_V1.safetensors] for UNet [/content/Fooocus/models/checkpoints/realisticStockPhoto_v20.safetensors] with 722 keys at weight 0.25.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] wearing a casual crop top and jeans, beautiful, detailed full perfect cute pretty futuristic background, dramatic light, cinematic, complex, highly structured, expressive, elegant, color set, lovely, sharp focus, professional, rich charming, marvelous, thought spectacular, epic, stunning, gorgeous, colossal, brilliant, symmetry, intricate, fantastic, amazing, awesome, fabulous, fancy\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.11 seconds\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Image processing ...\n",
            "Upscaling image with shape (712, 731, 3) ...\n",
            "[Fooocus] VAE Inpaint encoding ...\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.61 seconds\n",
            "[Fooocus] VAE encoding ...\n",
            "Final resolution is (896, 1152), latent is (1024, 960).\n",
            "[Parameters] Denoising Strength = 1\n",
            "[Parameters] Initial Latent shape: torch.Size([1, 4, 120, 128])\n",
            "Preparation time: 14.39 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/1 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.36 seconds\n",
            " 80% 24/30 [00:22<00:05,  1.03it/s]Requested to load SDXL\n",
            "Loading 1 new model\n",
            "unload clone 0\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.59 seconds\n",
            "Refiner Swapped\n",
            "100% 30/30 [00:28<00:00,  1.04it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.25 seconds\n",
            "[Fooocus] Saving image 1/1 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-08-26/log.html\n",
            "Generating and saving time: 33.11 seconds\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 33.11 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 47.52 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.90 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 108191772911893309\n",
            "[Parameters] CFG = 3\n",
            "[Fooocus] Downloading upscale models ...\n",
            "[Fooocus] Downloading inpainter ...\n",
            "[Inpaint] Current inpaint model is /content/Fooocus/models/inpaint/inpaint_v26.fooocus.patch\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 30 - 24\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Synthetic Refiner Activated\n",
            "Synthetic Refiner Activated\n",
            "Request to load LoRAs [('SDXL_FILM_PHOTOGRAPHY_STYLE_V1.safetensors', 0.25)] for model [/content/Fooocus/models/checkpoints/realisticStockPhoto_v20.safetensors].\n",
            "Loaded LoRA [/content/Fooocus/models/loras/SDXL_FILM_PHOTOGRAPHY_STYLE_V1.safetensors] for UNet [/content/Fooocus/models/checkpoints/realisticStockPhoto_v20.safetensors] with 722 keys at weight 0.25.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] wearing jeans, full focus, highly detailed, cinematic, elegant, intricate, perfect composition, innocent, fine detail, beautiful dynamic, lovely colors, clear background, inspired, rich deep vivid color, ambient dramatic light, creative, epic, stunning, gorgeous, great symmetry, thought, luxury, winning, awesome, fantastic, elaborate, brilliant, professional, best, surreal\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.11 seconds\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Image processing ...\n",
            "Upscaling image with shape (712, 731, 3) ...\n",
            "[Fooocus] VAE Inpaint encoding ...\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.60 seconds\n",
            "[Fooocus] VAE encoding ...\n",
            "Final resolution is (896, 1152), latent is (1024, 960).\n",
            "[Parameters] Denoising Strength = 1\n",
            "[Parameters] Initial Latent shape: torch.Size([1, 4, 120, 128])\n",
            "Preparation time: 14.59 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/1 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.51 seconds\n",
            " 80% 24/30 [00:22<00:05,  1.03it/s]Requested to load SDXL\n",
            "Loading 1 new model\n",
            "unload clone 0\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.70 seconds\n",
            "Refiner Swapped\n",
            "100% 30/30 [00:29<00:00,  1.03it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.24 seconds\n",
            "[Fooocus] Checking for NSFW content ...\n",
            "Downloading: \"https://huggingface.co/mashb1t/misc/resolve/main/stable-diffusion-safety-checker.bin\" to /content/Fooocus/models/safety_checker/stable-diffusion-safety-checker.bin\n",
            "\n",
            "100% 1.13G/1.13G [00:46<00:00, 26.4MB/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py\", line 402, in cached_file\n",
            "    resolved_file = hf_hub_download(\n",
            "                    ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_validators.py\", line 106, in _inner_fn\n",
            "    validate_repo_id(arg_value)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_validators.py\", line 154, in validate_repo_id\n",
            "    raise HFValidationError(\n",
            "huggingface_hub.errors.HFValidationError: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/content/Fooocus/models/safety_checker/stable-diffusion-safety-checker.bin'. Use `repo_type` argument if needed.\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Fooocus/modules/async_worker.py\", line 1471, in worker\n",
            "    handler(task)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/modules/async_worker.py\", line 1286, in handler\n",
            "    imgs, img_paths, current_progress = process_task(all_steps, async_task, callback, controlnet_canny_path,\n",
            "                                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/modules/async_worker.py\", line 319, in process_task\n",
            "    imgs = default_censor(imgs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/extras/censor.py\", line 40, in censor\n",
            "    self.init()\n",
            "  File \"/content/Fooocus/extras/censor.py\", line 29, in init\n",
            "    model = StableDiffusionSafetyChecker.from_pretrained(safety_checker_model, config=clip_config)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\", line 3151, in from_pretrained\n",
            "    _adapter_model_path = find_adapter_config_file(\n",
            "                          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/utils/peft_utils.py\", line 88, in find_adapter_config_file\n",
            "    adapter_cached_filename = cached_file(\n",
            "                              ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py\", line 466, in cached_file\n",
            "    raise EnvironmentError(\n",
            "OSError: Incorrect path_or_model_id: '/content/Fooocus/models/safety_checker/stable-diffusion-safety-checker.bin'. Please provide either the path to a local folder or the repo_id of a model on the Hub.\n",
            "Total time: 93.90 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 6029463158888897158\n",
            "[Parameters] CFG = 3\n",
            "[Fooocus] Downloading upscale models ...\n",
            "[Fooocus] Downloading inpainter ...\n",
            "[Inpaint] Current inpaint model is /content/Fooocus/models/inpaint/inpaint_v26.fooocus.patch\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 30 - 24\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Synthetic Refiner Activated\n",
            "Synthetic Refiner Activated\n",
            "Request to load LoRAs [('SDXL_FILM_PHOTOGRAPHY_STYLE_V1.safetensors', 0.25)] for model [/content/Fooocus/models/checkpoints/realisticStockPhoto_v20.safetensors].\n",
            "Loaded LoRA [/content/Fooocus/models/loras/SDXL_FILM_PHOTOGRAPHY_STYLE_V1.safetensors] for UNet [/content/Fooocus/models/checkpoints/realisticStockPhoto_v20.safetensors] with 722 keys at weight 0.25.\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.01 seconds\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] wearing jeans, cute, perfect detailed, amazing quality, highly detail, intricate, atmosphere, full color, cinematic, elegant, beautiful, thought, dramatic, epic, artistic, sharp focus, professional composition, cool, glorious, colorful, light, iconic, fine, surreal, open background, creative, positive, adventurous, thoughtful, glowing, vibrant, magical, determined\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.11 seconds\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Image processing ...\n",
            "Upscaling image with shape (712, 731, 3) ...\n",
            "[Fooocus] VAE Inpaint encoding ...\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.59 seconds\n",
            "[Fooocus] VAE encoding ...\n",
            "Final resolution is (896, 1152), latent is (1024, 960).\n",
            "[Parameters] Denoising Strength = 1\n",
            "[Parameters] Initial Latent shape: torch.Size([1, 4, 120, 128])\n",
            "Preparation time: 17.14 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/1 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.38 seconds\n",
            " 80% 24/30 [00:22<00:05,  1.04it/s]Requested to load SDXL\n",
            "Loading 1 new model\n",
            "unload clone 0\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.59 seconds\n",
            "Refiner Swapped\n",
            "100% 30/30 [00:29<00:00,  1.03it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.26 seconds\n",
            "[Fooocus] Checking for NSFW content ...\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Fooocus/modules/async_worker.py\", line 1471, in worker\n",
            "    handler(task)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/modules/async_worker.py\", line 1286, in handler\n",
            "    imgs, img_paths, current_progress = process_task(all_steps, async_task, callback, controlnet_canny_path,\n",
            "                                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/modules/async_worker.py\", line 319, in process_task\n",
            "    imgs = default_censor(imgs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/extras/censor.py\", line 41, in censor\n",
            "    model_management.load_model_gpu(self.safety_checker_model)\n",
            "  File \"/content/Fooocus/ldm_patched/modules/model_management.py\", line 443, in load_model_gpu\n",
            "    return load_models_gpu([model])\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/modules/patch.py\", line 447, in patched_load_models_gpu\n",
            "    y = ldm_patched.modules.model_management.load_models_gpu_origin(*args, **kwargs)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/ldm_patched/modules/model_management.py\", line 388, in load_models_gpu\n",
            "    loaded_model = LoadedModel(x)\n",
            "                   ^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/ldm_patched/modules/model_management.py\", line 280, in __init__\n",
            "    self.device = model.load_device\n",
            "                  ^^^^^^^^^^^^^^^^^\n",
            "AttributeError: 'NoneType' object has no attribute 'load_device'\n",
            "Total time: 49.99 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 7870814803270711761\n",
            "[Parameters] CFG = 3\n",
            "[Fooocus] Downloading control models ...\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 30 - 15\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "Request to load LoRAs [('SDXL_FILM_PHOTOGRAPHY_STYLE_V1.safetensors', 0.25)] for model [/content/Fooocus/models/checkpoints/realisticStockPhoto_v20.safetensors].\n",
            "Loaded LoRA [/content/Fooocus/models/loras/SDXL_FILM_PHOTOGRAPHY_STYLE_V1.safetensors] for UNet [/content/Fooocus/models/checkpoints/realisticStockPhoto_v20.safetensors] with 722 keys at weight 0.25.\n",
            "Loaded LoRA [/content/Fooocus/models/loras/SDXL_FILM_PHOTOGRAPHY_STYLE_V1.safetensors] for CLIP [/content/Fooocus/models/checkpoints/realisticStockPhoto_v20.safetensors] with 264 keys at weight 0.25.\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.02 seconds\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.19 seconds\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Image processing ...\n",
            "Detected 1 faces\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.72 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.45 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.25 seconds\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (1152, 896)\n",
            "Preparation time: 7.71 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/1 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.80 seconds\n",
            "100% 30/30 [00:35<00:00,  1.18s/it]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.32 seconds\n",
            "[Fooocus] Saving image 1/1 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-08-26/log.html\n",
            "Generating and saving time: 41.59 seconds\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 41.59 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 49.31 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.71 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 3672525710667841074\n",
            "[Parameters] CFG = 3\n",
            "[Fooocus] Downloading control models ...\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 30 - 15\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.12 seconds\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Image processing ...\n",
            "Detected 1 faces\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.72 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.44 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.24 seconds\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (1152, 896)\n",
            "Preparation time: 5.88 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/1 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.77 seconds\n",
            "100% 30/30 [00:35<00:00,  1.19s/it]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.25 seconds\n",
            "[Fooocus] Saving image 1/1 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-08-26/log.html\n",
            "Generating and saving time: 39.63 seconds\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 39.63 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 45.55 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.98 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 3672525710667841074\n",
            "[Parameters] CFG = 3\n",
            "[Fooocus] Downloading control models ...\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 30 - 15\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] Realistic portrait of hot Swedish 21 year old model, blonde hair, blue eyes, takes a selfie with her phone horizontally in front of a mirror, wearing a casual crop top and jeans, attractive, sublime, highly detailed, very aesthetic, glowing, holy, mystical, dramatic light, sharp focus, intricate, extremely coherent, colorful, artistic, fine detail, epic composition\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.12 seconds\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Image processing ...\n",
            "Detected 1 faces\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.73 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.43 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.23 seconds\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (1152, 896)\n",
            "Preparation time: 7.04 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/1 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.76 seconds\n",
            " 63% 19/30 [00:25<00:14,  1.32s/it]\n",
            "User stopped\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 26.14 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 33.21 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.87 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 3672525710667841074\n",
            "[Parameters] CFG = 3\n",
            "[Fooocus] Downloading control models ...\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 30 - 15\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] Realistic portrait, dramatic cinematic, artistic, perfect detailed intricate stunning fine detail, inspired, beautiful, glossy deep colors amazing, shiny great color, elegant, epic, awesome, fantastic, atmosphere, cool, striking, highly distinguished, brilliant, symmetry, outstanding, magnificent, delicate, complex, luxury, elite, elaborate, pretty, incredible, cheerful, splendid, marvelous, pure\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.11 seconds\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Image processing ...\n",
            "Detected 1 faces\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.77 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.41 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.22 seconds\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (1152, 896)\n",
            "Preparation time: 7.38 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/1 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.75 seconds\n",
            " 87% 26/30 [00:33<00:05,  1.28s/it]\n",
            "User stopped\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 34.30 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 41.69 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.98 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 3672525710667841074\n",
            "[Parameters] CFG = 3\n",
            "[Fooocus] Downloading control models ...\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 30 - 15\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] Realistic portrait, dramatic cinematic, artistic, perfect detailed intricate stunning fine detail, inspired, beautiful, glossy deep colors amazing, shiny great color, elegant, epic, awesome, fantastic, atmosphere, cool, striking, highly distinguished, brilliant, symmetry, outstanding, magnificent, delicate, complex, luxury, elite, elaborate, pretty, incredible, cheerful, splendid, marvelous, pure\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.11 seconds\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Image processing ...\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.70 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.40 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.29 seconds\n",
            "Detected 1 faces\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.50 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.41 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.24 seconds\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (1152, 896)\n",
            "Preparation time: 7.64 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/1 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.77 seconds\n",
            " 60% 18/30 [00:17<00:11,  1.02it/s]\n",
            "User stopped\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 18.50 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 26.16 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.85 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 3672525710667841074\n",
            "[Parameters] CFG = 3\n",
            "[Fooocus] Downloading control models ...\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 30 - 15\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] Realistic portrait, dramatic cinematic, artistic, perfect detailed intricate stunning fine detail, inspired, beautiful, glossy deep colors amazing, shiny great color, elegant, epic, awesome, fantastic, atmosphere, cool, striking, highly distinguished, brilliant, symmetry, outstanding, magnificent, delicate, complex, luxury, elite, elaborate, pretty, incredible, cheerful, splendid, marvelous, pure\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.11 seconds\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Image processing ...\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.67 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.37 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.21 seconds\n",
            "Detected 1 faces\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.53 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.42 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.24 seconds\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (1152, 896)\n",
            "Preparation time: 7.47 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/1 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.83 seconds\n",
            " 17% 5/30 [00:05<00:28,  1.14s/it]\n",
            "User stopped\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 6.54 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 14.03 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.82 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 3672525710667841074\n",
            "[Parameters] CFG = 3\n",
            "[Fooocus] Downloading control models ...\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 30 - 15\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] Realistic portrait, dramatic cinematic, artistic, perfect detailed intricate stunning fine detail, inspired, beautiful, glossy deep colors amazing, shiny great color, elegant, epic, awesome, fantastic, atmosphere, cool, striking, highly distinguished, brilliant, symmetry, outstanding, magnificent, delicate, complex, luxury, elite, elaborate, pretty, incredible, cheerful, splendid, marvelous, pure\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.11 seconds\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Image processing ...\n",
            "Detected 1 faces\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.76 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.40 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.21 seconds\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (1152, 896)\n",
            "Preparation time: 8.69 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/1 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.74 seconds\n",
            "100% 30/30 [00:36<00:00,  1.22s/it]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.25 seconds\n",
            "[Fooocus] Saving image 1/1 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-08-26/log.html\n",
            "Generating and saving time: 41.24 seconds\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 41.24 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 49.96 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.92 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 3672525710667841074\n",
            "[Parameters] CFG = 3\n",
            "[Fooocus] Downloading control models ...\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 30 - 15\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] Realistic, full color, cinematic, intricate, elegant, highly detailed, extremely aesthetic quality, illuminated, rich deep colors, inspired, draped, dramatic background, epic composition, solid, beautiful, pristine, vibrant, complex, amazing fine detail, enhanced, symmetry, light, magnificent, luxury, awesome, elaborate, creative, coherent, cheerful, lovely, marvelous, pure\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.12 seconds\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Image processing ...\n",
            "Detected 1 faces\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.74 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.49 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.26 seconds\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (1152, 896)\n",
            "Preparation time: 6.26 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/1 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.85 seconds\n",
            "100% 30/30 [00:36<00:00,  1.21s/it]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.28 seconds\n",
            "[Fooocus] Saving image 1/1 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-08-26/log.html\n",
            "Generating and saving time: 40.32 seconds\n",
            "[Fooocus] Processing enhance ...\n",
            "[Fooocus] Preparing enhancement 1/1 ...\n",
            "[Enhance] Searching for \"body\"\n",
            "Downloading: \"https://github.com/IDEA-Research/GroundingDINO/releases/download/v0.1.0-alpha/groundingdino_swint_ogc.pth\" to /content/Fooocus/models/inpaint/groundingdino_swint_ogc.pth\n",
            "\n",
            "100% 662M/662M [00:57<00:00, 12.2MB/s]\n",
            "/usr/local/lib/python3.12/dist-packages/torch/functional.py:554: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /pytorch/aten/src/ATen/native/TensorShape.cpp:4322.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "final text_encoder_type: bert-base-uncased\n",
            "tokenizer_config.json: 100% 48.0/48.0 [00:00<00:00, 355kB/s]\n",
            "config.json: 100% 570/570 [00:00<00:00, 4.52MB/s]\n",
            "vocab.txt: 100% 232k/232k [00:00<00:00, 3.46MB/s]\n",
            "tokenizer.json: 100% 466k/466k [00:00<00:00, 3.26MB/s]\n",
            "model.safetensors: 100% 440M/440M [00:52<00:00, 8.32MB/s]\n",
            "Requested to load GroundingDINO\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.42 seconds\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py:1060: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py:929: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/groundingdino/models/GroundingDINO/transformer.py:862: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=False):\n",
            "Downloading: \"https://huggingface.co/mashb1t/misc/resolve/main/sam_vit_b_01ec64.pth\" to /content/Fooocus/models/sam/sam_vit_b_01ec64.pth\n",
            "\n",
            "100% 358M/358M [00:14<00:00, 25.6MB/s]\n",
            "Requested to load Sam\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.39 seconds\n",
            "[Enhance] 3 boxes detected\n",
            "[Enhance] 3 segments detected in boxes\n",
            "[Enhance] 3 segments applied to mask\n",
            "[Fooocus] Downloading inpainter ...\n",
            "[Fooocus] Preparing enhance prompts ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "Request to load LoRAs [('SDXL_FILM_PHOTOGRAPHY_STYLE_V1.safetensors', 0.25), ('/content/Fooocus/models/inpaint/inpaint_v26.fooocus.patch', 1.0)] for model [/content/Fooocus/models/checkpoints/realisticStockPhoto_v20.safetensors].\n",
            "Loaded LoRA [/content/Fooocus/models/loras/SDXL_FILM_PHOTOGRAPHY_STYLE_V1.safetensors] for UNet [/content/Fooocus/models/checkpoints/realisticStockPhoto_v20.safetensors] with 722 keys at weight 0.25.\n",
            "Loaded LoRA [/content/Fooocus/models/loras/SDXL_FILM_PHOTOGRAPHY_STYLE_V1.safetensors] for CLIP [/content/Fooocus/models/checkpoints/realisticStockPhoto_v20.safetensors] with 264 keys at weight 0.25.\n",
            "Loaded LoRA [/content/Fooocus/models/inpaint/inpaint_v26.fooocus.patch] for UNet [/content/Fooocus/models/checkpoints/realisticStockPhoto_v20.safetensors] with 960 keys at weight 1.0.\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "[Fooocus Model Management] Moving model(s) has taken 2.14 seconds\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] Realistic, full color, cinematic, intricate, elegant, highly detailed, extremely aesthetic quality, illuminated, rich deep colors, inspired, draped, dramatic background, epic composition, solid, beautiful, pristine, vibrant, complex, amazing fine detail, enhanced, symmetry, light, magnificent, luxury, awesome, elaborate, creative, coherent, cheerful, lovely, marvelous, pure\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.11 seconds\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] VAE Inpaint encoding ...\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.45 seconds\n",
            "[Fooocus] VAE encoding ...\n",
            "Final resolution is (896, 1152), latent is (896, 1144).\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 5.53 seconds\n",
            "  0% 0/30 [00:01<?, ?it/s]\n",
            "User skipped\n",
            "Enhancement image time: 164.56 seconds\n",
            "Processing time (total): 204.88 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 211.17 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 2.05 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 3672525710667841074\n",
            "[Parameters] CFG = 3\n",
            "[Fooocus] Downloading control models ...\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 30 - 15\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "Request to load LoRAs [('SDXL_FILM_PHOTOGRAPHY_STYLE_V1.safetensors', 0.25)] for model [/content/Fooocus/models/checkpoints/realisticStockPhoto_v20.safetensors].\n",
            "Loaded LoRA [/content/Fooocus/models/loras/SDXL_FILM_PHOTOGRAPHY_STYLE_V1.safetensors] for UNet [/content/Fooocus/models/checkpoints/realisticStockPhoto_v20.safetensors] with 722 keys at weight 0.25.\n",
            "Loaded LoRA [/content/Fooocus/models/loras/SDXL_FILM_PHOTOGRAPHY_STYLE_V1.safetensors] for CLIP [/content/Fooocus/models/checkpoints/realisticStockPhoto_v20.safetensors] with 264 keys at weight 0.25.\n",
            "Requested to load SDXLClipModel\n",
            "Loading 1 new model\n",
            "unload clone 1\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.00 seconds\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] taking a selfie in a mirror, full background, beautiful, intricate, elegant, highly detailed, dramatic light, sharp focus, illuminated glowing, incredible fine detail, cinematic, complex, amazing composition, solid, epic, artistic color, dynamic, imposing, symmetry, vibrant, brilliant, thought driven, creative, professional, calm, thoughtful, pretty, attractive, cheerful, unique\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.11 seconds\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Image processing ...\n",
            "Detected 1 faces\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.74 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.45 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.25 seconds\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (1152, 896)\n",
            "Preparation time: 8.82 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/1 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 4.50 seconds\n",
            "100% 30/30 [00:38<00:00,  1.29s/it]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.26 seconds\n",
            "[Fooocus] Saving image 1/1 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-08-26/log.html\n",
            "Generating and saving time: 48.08 seconds\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 48.08 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 56.93 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.04 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 3672525710667841074\n",
            "[Parameters] CFG = 3\n",
            "[Fooocus] Downloading control models ...\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 30 - 15\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] Elegant blonde influencer in a silk dress, rooftop at sunset, city skyline behind her, full color, highly detailed, cinematic, extremely quality, very coherent, beautiful, symmetry, innocent, cute, inspired, charismatic, iconic, fine detail, pretty, enhanced, intricate, artistic, pleasing, creative, perfect scientific, expressive, lovely, delicate, warm colors\n",
            "[Fooocus] Preparing Fooocus text #2 ...\n",
            "[Prompt Expansion] Elegant blonde influencer in a silk dress, rooftop at sunset, city skyline behind her, full color, cinematic, extremely highly detailed, beautiful, stunning, sharp focus, very fine detail, elegant, complex, intricate, cool colors, amazing, awesome, great composition, professional, perfect, vibrant, symmetry, brilliant, best, dramatic, light, background, pristine\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.12 seconds\n",
            "[Fooocus] Encoding positive #2 ...\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Encoding negative #2 ...\n",
            "[Fooocus] Image processing ...\n",
            "Detected 1 faces\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.75 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.46 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.25 seconds\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (1152, 896)\n",
            "Preparation time: 6.76 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/2 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 3.58 seconds\n",
            "100% 30/30 [00:29<00:00,  1.03it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.32 seconds\n",
            "[Fooocus] Saving image 1/2 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-08-26/log.html\n",
            "Generating and saving time: 35.58 seconds\n",
            "[Fooocus] Preparing task 2/2 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.73 seconds\n",
            "100% 30/30 [00:27<00:00,  1.08it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.23 seconds\n",
            "[Fooocus] Saving image 2/2 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-08-26/log.html\n",
            "Generating and saving time: 31.14 seconds\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 66.72 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 73.54 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.99 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 3672525710667841074\n",
            "[Parameters] CFG = 3\n",
            "[Fooocus] Downloading control models ...\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 30\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] Elegant blonde influencer in a silk dress, rooftop at sunset, city skyline behind her in Sweden, cinematic, expansive, dramatic, detailed, sharp focus, very beautiful, intricate, elegant, highly detail, contemporary, professional, artistic, surreal, amazing, singular background, epic, romantic, vibrant, breathtaking, loving, symmetry, perfect, peaceful, pure, coherent\n",
            "[Fooocus] Preparing Fooocus text #2 ...\n",
            "[Prompt Expansion] Elegant blonde influencer in a silk dress, rooftop at sunset, city skyline behind her in Sweden, cinematic, elegant intricate, highly detailed, mystical, sharp focus, perfect light, very coherent, glowing colors, clear, symmetry, magical background, ambient, professional, great composition, expressive, innocent, rich deep aesthetic,,,, excellent detail, full color\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.12 seconds\n",
            "[Fooocus] Encoding positive #2 ...\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Encoding negative #2 ...\n",
            "[Fooocus] Image processing ...\n",
            "Detected 1 faces\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.74 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.47 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.25 seconds\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (1152, 896)\n",
            "Preparation time: 6.30 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/2 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.79 seconds\n",
            "100% 60/60 [00:56<00:00,  1.06it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.24 seconds\n",
            "[Fooocus] Saving image 1/2 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-08-26/log.html\n",
            "Generating and saving time: 60.33 seconds\n",
            "[Fooocus] Preparing task 2/2 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.73 seconds\n",
            " 48% 29/60 [00:27<00:29,  1.06it/s]\n",
            "User stopped\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 88.35 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 94.71 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.06 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 3672525710667841074\n",
            "[Parameters] CFG = 3\n",
            "[Fooocus] Downloading control models ...\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 30\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] Elegant blonde influencer in a silk dress, rooftop at sunset, city skyline behind her in Stockholm, elegant intricate, highly detailed, sharp focus, rich deep colors, cinematic, candid, warm light, futuristic, elaborate, very coherent, iconic, fine, inspiring, incredible detail, epic, artistic, complex, amazing color, vibrant, symmetry, illuminated, shining\n",
            "[Fooocus] Preparing Fooocus text #2 ...\n",
            "[Prompt Expansion] Elegant blonde influencer in a silk dress, rooftop at sunset, city skyline behind her in Stockholm, elegant, highly detailed, intricate, sharp focus, illuminated glowing, innocent, stunning composition, radiant light, open flowing color, very coherent, symmetry, massive, shiny, iconic, fine detail, clear, full, strong, crisp, aesthetic, amazing, emotional\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.12 seconds\n",
            "[Fooocus] Encoding positive #2 ...\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Encoding negative #2 ...\n",
            "[Fooocus] Image processing ...\n",
            "Detected 1 faces\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.74 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.51 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.27 seconds\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (1152, 896)\n",
            "Preparation time: 6.19 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/2 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.85 seconds\n",
            "100% 60/60 [00:56<00:00,  1.06it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.24 seconds\n",
            "[Fooocus] Saving image 1/2 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-08-26/log.html\n",
            "Generating and saving time: 60.51 seconds\n",
            "[Fooocus] Preparing task 2/2 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.83 seconds\n",
            "100% 60/60 [00:54<00:00,  1.09it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.23 seconds\n",
            "[Fooocus] Saving image 2/2 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-08-26/log.html\n",
            "Generating and saving time: 58.55 seconds\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 119.06 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 125.30 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.01 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 3672525710667841074\n",
            "[Parameters] CFG = 3\n",
            "[Fooocus] Downloading control models ...\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 30\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] Realistic portrait of hot Swedish 21 year old model, blonde hair, blue eyes in a silk dress, rooftop at sunset, city skyline behind her in Stockholm, perfect, attractive, highly detailed, intricate, sharp focus, massive background, cinematic, fine composition, ambient light, elegant, sublime, crisp detail, rich deep colors, dynamic, beautiful scenic full, very inspirational\n",
            "[Fooocus] Preparing Fooocus text #2 ...\n",
            "[Prompt Expansion] Realistic portrait of hot Swedish 21 year old model, blonde hair, blue eyes in a silk dress, rooftop at sunset, city skyline behind her in Stockholm, elegant, highly detailed, extremely sharp focus, intricate, fantastic composition, fine classic cinematic color, ambient light, dynamic background, professional magical, great composed, vibrant colors, creative, positive, cheerful, unique, artistic\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.12 seconds\n",
            "[Fooocus] Encoding positive #2 ...\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Encoding negative #2 ...\n",
            "[Fooocus] Image processing ...\n",
            "Detected 1 faces\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.74 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.46 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.25 seconds\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (1152, 896)\n",
            "Preparation time: 6.07 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/2 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.79 seconds\n",
            "  0% 0/60 [00:00<?, ?it/s]\n",
            "User stopped\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 1.71 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 7.80 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.98 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 3672525710667841074\n",
            "[Parameters] CFG = 3\n",
            "[Fooocus] Downloading control models ...\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 30\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] Realistic of hot Swedish 21 year old model, blonde hair, blue eyes in a silk dress, rooftop at sunset, city skyline behind her in Stockholm, perfect, attractive, cinematic, elegant, intricate, highly detailed, sharp focus, beautiful, futuristic, modern, inspired, draped, dramatic background, professional, artistic, very inspirational, extremely fine detail, color, clear\n",
            "[Fooocus] Preparing Fooocus text #2 ...\n",
            "[Prompt Expansion] Realistic of hot Swedish 21 year old model, blonde hair, blue eyes in a silk dress, rooftop at sunset, city skyline behind her in Stockholm, elegant, highly detailed, extremely sharp focus, intricate, fantastic composition, cinematic light, dynamic background, bright colors, open adorable, magical, shiny, rich deep vivid color, very inspirational, epic, brave, thought original\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.11 seconds\n",
            "[Fooocus] Encoding positive #2 ...\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Encoding negative #2 ...\n",
            "[Fooocus] Image processing ...\n",
            "Detected 1 faces\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.69 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.42 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.22 seconds\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (1152, 896)\n",
            "Preparation time: 5.76 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/2 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.74 seconds\n",
            "100% 60/60 [00:56<00:00,  1.06it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.25 seconds\n",
            "[Fooocus] Saving image 1/2 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-08-26/log.html\n",
            "Generating and saving time: 60.36 seconds\n",
            "[Fooocus] Preparing task 2/2 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.73 seconds\n",
            " 55% 33/60 [00:30<00:25,  1.07it/s]\n",
            "User stopped\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 91.98 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 97.79 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.95 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 3672525710667841074\n",
            "[Parameters] CFG = 3\n",
            "[Fooocus] Downloading control models ...\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 30\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] Realistic of Swedish 21 year old model, blue eyes in a silk dress, rooftop at sunset, city skyline behind her in Stockholm, perfect, attractive, cinematic, elegant, intricate, highly detailed, sharp focus, beautiful, futuristic, modern, inspired, draped, dramatic background, professional, artistic, very fine, epic, vibrant colors, amazing, awesome, incredible, creative\n",
            "[Fooocus] Preparing Fooocus text #2 ...\n",
            "[Prompt Expansion] Realistic of Swedish 21 year old model, blue eyes in a silk dress, rooftop at sunset, city skyline behind her in Stockholm, elegant, highly detailed, extremely sharp focus, intricate, fantastic composition, cinematic light, dynamic background, bright colors, beautiful, sublime, glowing, rich deep color, very inspirational, inspiring, thought original, cute, elite, iconic, fine\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.12 seconds\n",
            "[Fooocus] Encoding positive #2 ...\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Encoding negative #2 ...\n",
            "[Fooocus] Image processing ...\n",
            "Detected 1 faces\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.74 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.47 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.25 seconds\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (1152, 896)\n",
            "Preparation time: 6.11 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/2 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.80 seconds\n",
            "100% 60/60 [00:56<00:00,  1.06it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.26 seconds\n",
            "[Fooocus] Saving image 1/2 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-08-26/log.html\n",
            "Generating and saving time: 60.36 seconds\n",
            "[Fooocus] Preparing task 2/2 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.73 seconds\n",
            "100% 60/60 [00:54<00:00,  1.09it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.24 seconds\n",
            "[Fooocus] Saving image 2/2 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-08-26/log.html\n",
            "Generating and saving time: 58.44 seconds\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 118.80 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 124.95 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.97 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 3672525710667841074\n",
            "[Parameters] CFG = 3\n",
            "[Fooocus] Downloading control models ...\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 30\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] Realistic of Swedish 21 year old model, blue eyes in a blue bikini on a tropical beach, golden hour sunlight, playful smile, cinematic, elegant, intricate, highly detailed, sharp focus, beautiful, mystical, illuminated background, professional ambient light, unique, atmosphere, cute, charming, very inspirational, perfect, full color, artistic, positive, loving, caring, generous\n",
            "[Fooocus] Preparing Fooocus text #2 ...\n",
            "[Prompt Expansion] Realistic of Swedish 21 year old model, blue eyes in a blue bikini on a tropical beach, golden hour sunlight, playful smile, cinematic, modern fine classic, beautiful detailed intricate stunning amazing composition, sharp focus, very inspirational, warm light, epic background, dynamic dramatic ambient, rich vibrant colors, excellent composed, clear outstanding, elegant, perfect artistic, aesthetic,, sincere\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.12 seconds\n",
            "[Fooocus] Encoding positive #2 ...\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Encoding negative #2 ...\n",
            "[Fooocus] Image processing ...\n",
            "Detected 1 faces\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.75 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.46 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.25 seconds\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (1152, 896)\n",
            "Preparation time: 6.17 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/2 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.78 seconds\n",
            " 43% 26/60 [00:27<00:36,  1.07s/it]\n",
            "User stopped\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 28.71 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 34.90 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.91 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 3672525710667841074\n",
            "[Parameters] CFG = 3\n",
            "[Fooocus] Downloading control models ...\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 30\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] Realistic of Swedish 21 year old model, blue eyes in a blue bikini on a tropical beach, golden hour sunlight, playful smile in Stockholm, modern contemporary, highly detailed, cinematic, fine detail, intricate, elegant, luxury, elite, sharp focus, inspired, rich vibrant colors, epic composition, very inspirational, innocent, generous, thought, iconic, warm light, magic\n",
            "[Fooocus] Preparing Fooocus text #2 ...\n",
            "[Prompt Expansion] Realistic of Swedish 21 year old model, blue eyes in a blue bikini on a tropical beach, golden hour sunlight, playful smile in Stockholm, cinematic, modern fine classic, beautiful detailed intricate highly detail, elegant, luxury, elite, innocent, epic, mystical, open, rich vibrant color, sharp focus, excellent composition, ambient light, dynamic dramatic radiant colors, aesthetic\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.12 seconds\n",
            "[Fooocus] Encoding positive #2 ...\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Encoding negative #2 ...\n",
            "[Fooocus] Image processing ...\n",
            "Detected 1 faces\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.82 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.48 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.26 seconds\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (1152, 896)\n",
            "Preparation time: 6.19 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/2 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.86 seconds\n",
            "100% 60/60 [00:56<00:00,  1.06it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.25 seconds\n",
            "[Fooocus] Saving image 1/2 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-08-26/log.html\n",
            "Generating and saving time: 60.47 seconds\n",
            "[Fooocus] Preparing task 2/2 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.78 seconds\n",
            "100% 60/60 [00:54<00:00,  1.09it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.24 seconds\n",
            "[Fooocus] Saving image 2/2 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-08-26/log.html\n",
            "Generating and saving time: 58.48 seconds\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 118.95 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 125.19 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.06 seconds\n"
          ]
        }
      ],
      "source": [
        "!pip install pygit2==1.15.1\n",
        "%cd /content\n",
        "!git clone https://github.com/lllyasviel/Fooocus.git\n",
        "%cd /content/Fooocus\n",
        "!python entry_with_update.py --share --always-high-vram\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4E7GldmOMoSX"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}